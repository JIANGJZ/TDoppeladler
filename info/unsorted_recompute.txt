Namespace(backend='vllm', dataset='/home/jiangjz/llm/TDoppeladler/dataset/ShareGPT_V3_unfiltered_cleaned_split.json', dtype='auto', enforce_eager=False, hf_max_batch_size=None, input_len=None, max_model_len=None, model='/home/jiangjz/llm/TDoppeladler/model/vicuna-7b-v1.5', n=1, num_prompts=1000, output_len=None, quantization=None, seed=0, tensor_parallel_size=1, tokenizer='/home/jiangjz/llm/TDoppeladler/model/vicuna-7b-v1.5', trust_remote_code=False, use_beam_search=False)
ModelConfig hidden_size=4096, head_size=128, swap_space_bytes=32, num_kv_heads=32        num_layers=32
CacheConfig block_size=16, gpu_memory_utilization=0.9, swap_space_bytes=34359738368,         sliding_window=None
SchedulerConfig max_num_batched_tokens=4096, max_model_len=4096, max_num_seqs=256,         max_paddings=256
INFO 12-28 15:57:15 llm_engine.py:74] Initializing an LLM engine with config: model='/home/jiangjz/llm/TDoppeladler/model/vicuna-7b-v1.5', tokenizer='/home/jiangjz/llm/TDoppeladler/model/vicuna-7b-v1.5', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, max_seq_len=4096, download_dir=None, load_format=auto, tensor_parallel_size=1, quantization=None, enforce_eager=False, seed=0)
input_metadata = InputMetadata(prompt_lens=[16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16], num_prompts=256, max_context_len=None,)
INFO 12-28 15:57:21 llm_engine.py:236] # GPU blocks: 954, # CPU blocks: 4096
INFO 12-28 15:57:26 model_runner.py:403] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 12-28 15:57:26 model_runner.py:407] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode.
input_metadata = InputMetadata(prompt_lens=[], num_prompts=0, max_context_len=4096,)
input_metadata = InputMetadata(prompt_lens=[], num_prompts=0, max_context_len=4096,)
input_metadata = InputMetadata(prompt_lens=[], num_prompts=0, max_context_len=4096,)
input_metadata = InputMetadata(prompt_lens=[], num_prompts=0, max_context_len=4096,)
input_metadata = InputMetadata(prompt_lens=[], num_prompts=0, max_context_len=4096,)
input_metadata = InputMetadata(prompt_lens=[], num_prompts=0, max_context_len=4096,)
input_metadata = InputMetadata(prompt_lens=[], num_prompts=0, max_context_len=4096,)
input_metadata = InputMetadata(prompt_lens=[], num_prompts=0, max_context_len=4096,)
input_metadata = InputMetadata(prompt_lens=[], num_prompts=0, max_context_len=4096,)
input_metadata = InputMetadata(prompt_lens=[], num_prompts=0, max_context_len=4096,)
input_metadata = InputMetadata(prompt_lens=[], num_prompts=0, max_context_len=4096,)
input_metadata = InputMetadata(prompt_lens=[], num_prompts=0, max_context_len=4096,)
input_metadata = InputMetadata(prompt_lens=[], num_prompts=0, max_context_len=4096,)
input_metadata = InputMetadata(prompt_lens=[], num_prompts=0, max_context_len=4096,)
input_metadata = InputMetadata(prompt_lens=[], num_prompts=0, max_context_len=4096,)
input_metadata = InputMetadata(prompt_lens=[], num_prompts=0, max_context_len=4096,)
input_metadata = InputMetadata(prompt_lens=[], num_prompts=0, max_context_len=4096,)
input_metadata = InputMetadata(prompt_lens=[], num_prompts=0, max_context_len=4096,)
input_metadata = InputMetadata(prompt_lens=[], num_prompts=0, max_context_len=4096,)
input_metadata = InputMetadata(prompt_lens=[], num_prompts=0, max_context_len=4096,)
input_metadata = InputMetadata(prompt_lens=[], num_prompts=0, max_context_len=4096,)
input_metadata = InputMetadata(prompt_lens=[], num_prompts=0, max_context_len=4096,)
input_metadata = InputMetadata(prompt_lens=[], num_prompts=0, max_context_len=4096,)
input_metadata = InputMetadata(prompt_lens=[], num_prompts=0, max_context_len=4096,)
input_metadata = InputMetadata(prompt_lens=[], num_prompts=0, max_context_len=4096,)
input_metadata = InputMetadata(prompt_lens=[], num_prompts=0, max_context_len=4096,)
input_metadata = InputMetadata(prompt_lens=[], num_prompts=0, max_context_len=4096,)
input_metadata = InputMetadata(prompt_lens=[], num_prompts=0, max_context_len=4096,)
input_metadata = InputMetadata(prompt_lens=[], num_prompts=0, max_context_len=4096,)
input_metadata = InputMetadata(prompt_lens=[], num_prompts=0, max_context_len=4096,)
input_metadata = InputMetadata(prompt_lens=[], num_prompts=0, max_context_len=4096,)
input_metadata = InputMetadata(prompt_lens=[], num_prompts=0, max_context_len=4096,)
input_metadata = InputMetadata(prompt_lens=[], num_prompts=0, max_context_len=4096,)
input_metadata = InputMetadata(prompt_lens=[], num_prompts=0, max_context_len=4096,)
input_metadata = InputMetadata(prompt_lens=[], num_prompts=0, max_context_len=4096,)
input_metadata = InputMetadata(prompt_lens=[], num_prompts=0, max_context_len=4096,)
input_metadata = InputMetadata(prompt_lens=[], num_prompts=0, max_context_len=4096,)
input_metadata = InputMetadata(prompt_lens=[], num_prompts=0, max_context_len=4096,)
input_metadata = InputMetadata(prompt_lens=[], num_prompts=0, max_context_len=4096,)
input_metadata = InputMetadata(prompt_lens=[], num_prompts=0, max_context_len=4096,)
input_metadata = InputMetadata(prompt_lens=[], num_prompts=0, max_context_len=4096,)
input_metadata = InputMetadata(prompt_lens=[], num_prompts=0, max_context_len=4096,)
input_metadata = InputMetadata(prompt_lens=[], num_prompts=0, max_context_len=4096,)
input_metadata = InputMetadata(prompt_lens=[], num_prompts=0, max_context_len=4096,)
input_metadata = InputMetadata(prompt_lens=[], num_prompts=0, max_context_len=4096,)
input_metadata = InputMetadata(prompt_lens=[], num_prompts=0, max_context_len=4096,)
input_metadata = InputMetadata(prompt_lens=[], num_prompts=0, max_context_len=4096,)
input_metadata = InputMetadata(prompt_lens=[], num_prompts=0, max_context_len=4096,)
input_metadata = InputMetadata(prompt_lens=[], num_prompts=0, max_context_len=4096,)
input_metadata = InputMetadata(prompt_lens=[], num_prompts=0, max_context_len=4096,)
input_metadata = InputMetadata(prompt_lens=[], num_prompts=0, max_context_len=4096,)
input_metadata = InputMetadata(prompt_lens=[], num_prompts=0, max_context_len=4096,)
input_metadata = InputMetadata(prompt_lens=[], num_prompts=0, max_context_len=4096,)
input_metadata = InputMetadata(prompt_lens=[], num_prompts=0, max_context_len=4096,)
input_metadata = InputMetadata(prompt_lens=[], num_prompts=0, max_context_len=4096,)
input_metadata = InputMetadata(prompt_lens=[], num_prompts=0, max_context_len=4096,)
input_metadata = InputMetadata(prompt_lens=[], num_prompts=0, max_context_len=4096,)
input_metadata = InputMetadata(prompt_lens=[], num_prompts=0, max_context_len=4096,)
input_metadata = InputMetadata(prompt_lens=[], num_prompts=0, max_context_len=4096,)
input_metadata = InputMetadata(prompt_lens=[], num_prompts=0, max_context_len=4096,)
input_metadata = InputMetadata(prompt_lens=[], num_prompts=0, max_context_len=4096,)
input_metadata = InputMetadata(prompt_lens=[], num_prompts=0, max_context_len=4096,)
input_metadata = InputMetadata(prompt_lens=[], num_prompts=0, max_context_len=4096,)
input_metadata = InputMetadata(prompt_lens=[], num_prompts=0, max_context_len=4096,)
input_metadata = InputMetadata(prompt_lens=[], num_prompts=0, max_context_len=4096,)
input_metadata = InputMetadata(prompt_lens=[], num_prompts=0, max_context_len=4096,)
input_metadata = InputMetadata(prompt_lens=[], num_prompts=0, max_context_len=4096,)
input_metadata = InputMetadata(prompt_lens=[], num_prompts=0, max_context_len=4096,)
input_metadata = InputMetadata(prompt_lens=[], num_prompts=0, max_context_len=4096,)
input_metadata = InputMetadata(prompt_lens=[], num_prompts=0, max_context_len=4096,)
INFO 12-28 15:57:28 model_runner.py:449] Graph capturing finished in 2 secs.
promt select exit padding exceed_paddings=663, cur_paddings=141, exceeed_seq=470
input_metadata = InputMetadata(prompt_lens=[68, 209], num_prompts=2, max_context_len=None,)
promt select exit padding exceed_paddings=453, cur_paddings=0, exceeed_seq=17
input_metadata = InputMetadata(prompt_lens=[470], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=313, cur_paddings=202, exceeed_seq=27
input_metadata = InputMetadata(prompt_lens=[17, 57, 138], num_prompts=3, max_context_len=None,)
promt select exit padding exceed_paddings=432, cur_paddings=0, exceeed_seq=459
input_metadata = InputMetadata(prompt_lens=[27], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=415, cur_paddings=0, exceeed_seq=44
input_metadata = InputMetadata(prompt_lens=[459], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=987, cur_paddings=11, exceeed_seq=532
input_metadata = InputMetadata(prompt_lens=[44, 33], num_prompts=2, max_context_len=None,)
promt select exit padding exceed_paddings=504, cur_paddings=0, exceeed_seq=28
input_metadata = InputMetadata(prompt_lens=[532], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=1211, cur_paddings=125, exceeed_seq=226
input_metadata = InputMetadata(prompt_lens=[28, 14, 14, 38, 45, 6], num_prompts=6, max_context_len=None,)
promt select exit padding exceed_paddings=945, cur_paddings=249, exceeed_seq=458
input_metadata = InputMetadata(prompt_lens=[226, 36, 167], num_prompts=3, max_context_len=None,)
promt select exit padding exceed_paddings=422, cur_paddings=0, exceeed_seq=36
input_metadata = InputMetadata(prompt_lens=[458], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=1353, cur_paddings=18, exceeed_seq=481
input_metadata = InputMetadata(prompt_lens=[36, 28, 26], num_prompts=3, max_context_len=None,)
promt select exit padding exceed_paddings=311, cur_paddings=164, exceeed_seq=609
input_metadata = InputMetadata(prompt_lens=[481, 475, 560], num_prompts=3, max_context_len=None,)
promt select exit padding exceed_paddings=588, cur_paddings=0, exceeed_seq=21
input_metadata = InputMetadata(prompt_lens=[609], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=308, cur_paddings=0, exceeed_seq=329
input_metadata = InputMetadata(prompt_lens=[21], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=544, cur_paddings=190, exceeed_seq=696
input_metadata = InputMetadata(prompt_lens=[329, 519], num_prompts=2, max_context_len=None,)
promt select exit padding exceed_paddings=503, cur_paddings=220, exceeed_seq=413
input_metadata = InputMetadata(prompt_lens=[696, 476], num_prompts=2, max_context_len=None,)
promt select exit padding exceed_paddings=382, cur_paddings=0, exceeed_seq=31
input_metadata = InputMetadata(prompt_lens=[413], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=311, cur_paddings=35, exceeed_seq=123
input_metadata = InputMetadata(prompt_lens=[31, 21, 6], num_prompts=3, max_context_len=None,)
promt select exit padding exceed_paddings=631, cur_paddings=0, exceeed_seq=754
input_metadata = InputMetadata(prompt_lens=[123], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=733, cur_paddings=0, exceeed_seq=21
input_metadata = InputMetadata(prompt_lens=[754], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=314, cur_paddings=189, exceeed_seq=85
input_metadata = InputMetadata(prompt_lens=[21, 210], num_prompts=2, max_context_len=None,)
promt select exit padding exceed_paddings=455, cur_paddings=0, exceeed_seq=540
input_metadata = InputMetadata(prompt_lens=[85], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=351, cur_paddings=89, exceeed_seq=278
input_metadata = InputMetadata(prompt_lens=[540, 451], num_prompts=2, max_context_len=None,)
promt select exit padding exceed_paddings=264, cur_paddings=0, exceeed_seq=14
input_metadata = InputMetadata(prompt_lens=[278], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=1574, cur_paddings=2, exceeed_seq=802
input_metadata = InputMetadata(prompt_lens=[14, 16], num_prompts=2, max_context_len=None,)
promt select exit padding exceed_paddings=635, cur_paddings=0, exceeed_seq=167
input_metadata = InputMetadata(prompt_lens=[802], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=580, cur_paddings=224, exceeed_seq=35
input_metadata = InputMetadata(prompt_lens=[167, 391], num_prompts=2, max_context_len=None,)
promt select exceed tokens total_tokens=4314, new_tokens=719
input_metadata = InputMetadata(prompt_lens=[35, 16, 15, 30, 25], num_prompts=5, max_context_len=None,)
promt select exit padding exceed_paddings=705, cur_paddings=0, exceeed_seq=14
input_metadata = InputMetadata(prompt_lens=[719], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=394, cur_paddings=0, exceeed_seq=408
input_metadata = InputMetadata(prompt_lens=[14], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=382, cur_paddings=0, exceeed_seq=26
input_metadata = InputMetadata(prompt_lens=[408], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=412, cur_paddings=0, exceeed_seq=438
input_metadata = InputMetadata(prompt_lens=[26], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=333, cur_paddings=0, exceeed_seq=105
input_metadata = InputMetadata(prompt_lens=[438], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=741, cur_paddings=0, exceeed_seq=846
input_metadata = InputMetadata(prompt_lens=[105], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[846], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=683, cur_paddings=0, exceeed_seq=20
input_metadata = InputMetadata(prompt_lens=[703], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[20], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[228], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=392, cur_paddings=0, exceeed_seq=12
input_metadata = InputMetadata(prompt_lens=[404], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=319, cur_paddings=0, exceeed_seq=331
input_metadata = InputMetadata(prompt_lens=[12], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=298, cur_paddings=0, exceeed_seq=33
input_metadata = InputMetadata(prompt_lens=[331], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=427, cur_paddings=0, exceeed_seq=460
input_metadata = InputMetadata(prompt_lens=[33], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=449, cur_paddings=0, exceeed_seq=11
input_metadata = InputMetadata(prompt_lens=[460], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[11, 9], num_prompts=2, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[672], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[883], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=277, cur_paddings=18, exceeed_seq=149
input_metadata = InputMetadata(prompt_lens=[390, 408], num_prompts=2, max_context_len=None,)
promt select exit padding exceed_paddings=303, cur_paddings=0, exceeed_seq=452
input_metadata = InputMetadata(prompt_lens=[149], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=360, cur_paddings=0, exceeed_seq=92
input_metadata = InputMetadata(prompt_lens=[452], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[92, 236], num_prompts=2, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[244], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=408, cur_paddings=0, exceeed_seq=15
input_metadata = InputMetadata(prompt_lens=[423], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=731, cur_paddings=5, exceeed_seq=378
input_metadata = InputMetadata(prompt_lens=[15, 10], num_prompts=2, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[378], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=469, cur_paddings=228, exceeed_seq=7
input_metadata = InputMetadata(prompt_lens=[248, 167, 101], num_prompts=3, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[7], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[10], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=556, cur_paddings=0, exceeed_seq=57
input_metadata = InputMetadata(prompt_lens=[613], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[57], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[283], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=661, cur_paddings=0, exceeed_seq=179
input_metadata = InputMetadata(prompt_lens=[840], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[179], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[259, 23], num_prompts=2, max_context_len=None,)
promt select exit padding exceed_paddings=807, cur_paddings=0, exceeed_seq=29
input_metadata = InputMetadata(prompt_lens=[836], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[29, 89, 35], num_prompts=3, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[167], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[232, 8], num_prompts=2, max_context_len=None,)
INFO 12-28 15:57:33 llm_engine.py:693] Avg past 5 seconds prompt throughput: 5813.5 tokens/s, Avg past 5 seconds real prompt throughput: 5251.3 tokens/s, Avg past 5 seconds generation throughput: 1111.6 tokens/s, total prompt throughput: 27508.0 tokens/s, total real prompt throughput: 24848.0 tokens/s, total final prompt throughput: 24838.0 tokens/s, total generation throughput: 3173.0 tokens/s, avg total prompt throughput: 5813.5 tokens/s, avg total real prompt throughput: 5251.3 tokens/s, avg total final prompt throughput: 5249.2 tokens/s, avg total generation throughput: 1111.6 tokens/s, Running: 67 reqs, Swapped: 0 reqs, Waiting: 899 reqs, GPU KV cache usage: 97.7%, CPU KV cache usage: 0.0%
input_metadata = InputMetadata(prompt_lens=[237, 11], num_prompts=2, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[943], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[946], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=360, cur_paddings=0, exceeed_seq=83
input_metadata = InputMetadata(prompt_lens=[443], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[83, 42], num_prompts=2, max_context_len=None,)
promt select exit padding exceed_paddings=449, cur_paddings=0, exceeed_seq=83
input_metadata = InputMetadata(prompt_lens=[532], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[83], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=513, cur_paddings=0, exceeed_seq=148
input_metadata = InputMetadata(prompt_lens=[661], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=611, cur_paddings=193, exceeed_seq=550
input_metadata = InputMetadata(prompt_lens=[148, 341], num_prompts=2, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[550], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[441], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[445], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=651, cur_paddings=0, exceeed_seq=31
input_metadata = InputMetadata(prompt_lens=[682], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[31], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[479], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[484], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=652, cur_paddings=0, exceeed_seq=37
input_metadata = InputMetadata(prompt_lens=[689], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[37], num_prompts=1, max_context_len=None,)
INFO 12-28 15:57:38 llm_engine.py:693] Avg past 5 seconds prompt throughput: 1774.0 tokens/s, Avg past 5 seconds real prompt throughput: 1680.6 tokens/s, Avg past 5 seconds generation throughput: 1606.1 tokens/s, total prompt throughput: 36703.0 tokens/s, total real prompt throughput: 33359.0 tokens/s, total final prompt throughput: 30058.0 tokens/s, total generation throughput: 11269.0 tokens/s, avg total prompt throughput: 3761.1 tokens/s, avg total real prompt throughput: 3418.4 tokens/s, avg total final prompt throughput: 3080.1 tokens/s, avg total generation throughput: 1429.8 tokens/s, Running: 50 reqs, Swapped: 0 reqs, Waiting: 886 reqs, GPU KV cache usage: 98.7%, CPU KV cache usage: 0.0%
input_metadata = InputMetadata(prompt_lens=[550], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[196], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[245], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[249, 199], num_prompts=2, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[289], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[300], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[306], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[250], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[321], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[330], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[335], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[554], num_prompts=1, max_context_len=None,)
INFO 12-28 15:57:43 llm_engine.py:693] Avg past 5 seconds prompt throughput: 772.4 tokens/s, Avg past 5 seconds real prompt throughput: 761.8 tokens/s, Avg past 5 seconds generation throughput: 1245.9 tokens/s, total prompt throughput: 40360.0 tokens/s, total real prompt throughput: 36966.0 tokens/s, total final prompt throughput: 30058.0 tokens/s, total generation throughput: 17518.0 tokens/s, avg total prompt throughput: 2733.8 tokens/s, avg total real prompt throughput: 2503.9 tokens/s, avg total final prompt throughput: 2036.0 tokens/s, avg total generation throughput: 1359.5 tokens/s, Running: 29 reqs, Swapped: 0 reqs, Waiting: 886 reqs, GPU KV cache usage: 96.3%, CPU KV cache usage: 0.0%
input_metadata = InputMetadata(prompt_lens=[627], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[641], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=653, cur_paddings=0, exceeed_seq=59
input_metadata = InputMetadata(prompt_lens=[712], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[59], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=653, cur_paddings=0, exceeed_seq=166
input_metadata = InputMetadata(prompt_lens=[819], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=301, cur_paddings=143, exceeed_seq=8
input_metadata = InputMetadata(prompt_lens=[166, 23], num_prompts=2, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[8, 14], num_prompts=2, max_context_len=None,)
promt select exit padding exceed_paddings=384, cur_paddings=0, exceeed_seq=410
input_metadata = InputMetadata(prompt_lens=[26], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[410], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=361, cur_paddings=0, exceeed_seq=21
input_metadata = InputMetadata(prompt_lens=[382], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[21, 67], num_prompts=2, max_context_len=None,)
promt select exit padding exceed_paddings=376, cur_paddings=0, exceeed_seq=9
input_metadata = InputMetadata(prompt_lens=[385], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=1211, cur_paddings=32, exceeed_seq=418
input_metadata = InputMetadata(prompt_lens=[9, 9, 25], num_prompts=3, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[418], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[427], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[437], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[673], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[78], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=818, cur_paddings=0, exceeed_seq=30
input_metadata = InputMetadata(prompt_lens=[848], num_prompts=1, max_context_len=None,)
INFO 12-28 15:57:48 llm_engine.py:693] Avg past 5 seconds prompt throughput: 2042.9 tokens/s, Avg past 5 seconds real prompt throughput: 1973.3 tokens/s, Avg past 5 seconds generation throughput: 875.6 tokens/s, total prompt throughput: 47577.0 tokens/s, total real prompt throughput: 43956.0 tokens/s, total final prompt throughput: 33565.0 tokens/s, total generation throughput: 21915.0 tokens/s, avg total prompt throughput: 2405.6 tokens/s, avg total real prompt throughput: 2222.5 tokens/s, avg total final prompt throughput: 1697.1 tokens/s, avg total generation throughput: 1224.3 tokens/s, Running: 30 reqs, Swapped: 0 reqs, Waiting: 867 reqs, GPU KV cache usage: 96.3%, CPU KV cache usage: 0.0%
input_metadata = InputMetadata(prompt_lens=[30, 31, 96, 17], num_prompts=4, max_context_len=None,)
promt select exit padding exceed_paddings=450, cur_paddings=91, exceeed_seq=6
input_metadata = InputMetadata(prompt_lens=[365, 274], num_prompts=2, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[6, 6], num_prompts=2, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[63, 99, 79, 27], num_prompts=4, max_context_len=None,)
promt select exit padding exceed_paddings=767, cur_paddings=0, exceeed_seq=10
input_metadata = InputMetadata(prompt_lens=[777], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[10], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=767, cur_paddings=0, exceeed_seq=13
input_metadata = InputMetadata(prompt_lens=[780], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[13, 30], num_prompts=2, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[125, 72], num_prompts=2, max_context_len=None,)
promt select exit padding exceed_paddings=767, cur_paddings=0, exceeed_seq=21
input_metadata = InputMetadata(prompt_lens=[788], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=351, cur_paddings=180, exceeed_seq=175
input_metadata = InputMetadata(prompt_lens=[21, 35, 118], num_prompts=3, max_context_len=None,)
promt select exit padding exceed_paddings=422, cur_paddings=0, exceeed_seq=597
input_metadata = InputMetadata(prompt_lens=[175], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[597], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[269, 245], num_prompts=2, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[255, 249, 72], num_prompts=3, max_context_len=None,)
promt select exit padding exceed_paddings=358, cur_paddings=0, exceeed_seq=6
input_metadata = InputMetadata(prompt_lens=[364], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[6], num_prompts=1, max_context_len=None,)
INFO 12-28 15:57:54 llm_engine.py:693] Avg past 5 seconds prompt throughput: 1404.3 tokens/s, Avg past 5 seconds real prompt throughput: 1224.9 tokens/s, Avg past 5 seconds generation throughput: 1074.0 tokens/s, total prompt throughput: 55405.0 tokens/s, total real prompt throughput: 50892.0 tokens/s, total final prompt throughput: 38412.0 tokens/s, total generation throughput: 27253.0 tokens/s, avg total prompt throughput: 2234.9 tokens/s, avg total real prompt throughput: 2052.9 tokens/s, avg total final prompt throughput: 1549.5 tokens/s, avg total generation throughput: 1189.4 tokens/s, Running: 31 reqs, Swapped: 0 reqs, Waiting: 845 reqs, GPU KV cache usage: 98.7%, CPU KV cache usage: 0.0%
input_metadata = InputMetadata(prompt_lens=[292], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=259, cur_paddings=9, exceeed_seq=299
input_metadata = InputMetadata(prompt_lens=[165, 174], num_prompts=2, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[299], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[337], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=359, cur_paddings=191, exceeed_seq=426
input_metadata = InputMetadata(prompt_lens=[342, 151], num_prompts=2, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[426], num_prompts=1, max_context_len=None,)
INFO 12-28 15:57:59 llm_engine.py:693] Avg past 5 seconds prompt throughput: 477.6 tokens/s, Avg past 5 seconds real prompt throughput: 428.8 tokens/s, Avg past 5 seconds generation throughput: 908.4 tokens/s, total prompt throughput: 57371.0 tokens/s, total real prompt throughput: 52658.0 tokens/s, total final prompt throughput: 38418.0 tokens/s, total generation throughput: 31822.0 tokens/s, avg total prompt throughput: 1924.4 tokens/s, avg total real prompt throughput: 1766.3 tokens/s, avg total final prompt throughput: 1288.7 tokens/s, avg total generation throughput: 1139.1 tokens/s, Running: 19 reqs, Swapped: 0 reqs, Waiting: 851 reqs, GPU KV cache usage: 97.8%, CPU KV cache usage: 0.0%
input_metadata = InputMetadata(prompt_lens=[335], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[256, 250], num_prompts=2, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[359], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=322, cur_paddings=196, exceeed_seq=433
input_metadata = InputMetadata(prompt_lens=[370, 174], num_prompts=2, max_context_len=None,)
promt select exit padding exceed_paddings=367, cur_paddings=0, exceeed_seq=66
input_metadata = InputMetadata(prompt_lens=[433], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[66], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[1017], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=335, cur_paddings=0, exceeed_seq=692
input_metadata = InputMetadata(prompt_lens=[1027], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=669, cur_paddings=0, exceeed_seq=23
input_metadata = InputMetadata(prompt_lens=[692], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=1683, cur_paddings=59, exceeed_seq=443
input_metadata = InputMetadata(prompt_lens=[23, 11, 37, 18], num_prompts=4, max_context_len=None,)
promt select exit padding exceed_paddings=438, cur_paddings=0, exceeed_seq=5
input_metadata = InputMetadata(prompt_lens=[443], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[5, 14], num_prompts=2, max_context_len=None,)
promt select exit padding exceed_paddings=394, cur_paddings=0, exceeed_seq=67
input_metadata = InputMetadata(prompt_lens=[461], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=283, cur_paddings=115, exceeed_seq=14
input_metadata = InputMetadata(prompt_lens=[67, 182], num_prompts=2, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[14], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[248], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=398, cur_paddings=0, exceeed_seq=8
input_metadata = InputMetadata(prompt_lens=[406], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[8], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=399, cur_paddings=0, exceeed_seq=15
input_metadata = InputMetadata(prompt_lens=[414], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[15], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=400, cur_paddings=0, exceeed_seq=23
input_metadata = InputMetadata(prompt_lens=[423], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=329, cur_paddings=220, exceeed_seq=17
input_metadata = InputMetadata(prompt_lens=[23, 126, 9], num_prompts=3, max_context_len=None,)
promt select exit padding exceed_paddings=424, cur_paddings=144, exceeed_seq=79
input_metadata = InputMetadata(prompt_lens=[17, 15, 39, 14, 10, 17, 17], num_prompts=7, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[79], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=573, cur_paddings=0, exceeed_seq=124
input_metadata = InputMetadata(prompt_lens=[697], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=291, cur_paddings=117, exceeed_seq=211
input_metadata = InputMetadata(prompt_lens=[124, 7], num_prompts=2, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[211, 5], num_prompts=2, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[221, 15], num_prompts=2, max_context_len=None,)
promt select exit padding exceed_paddings=593, cur_paddings=0, exceeed_seq=8
input_metadata = InputMetadata(prompt_lens=[601], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=317, cur_paddings=0, exceeed_seq=325
input_metadata = InputMetadata(prompt_lens=[8], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=404, cur_paddings=115, exceeed_seq=36
input_metadata = InputMetadata(prompt_lens=[325, 210], num_prompts=2, max_context_len=None,)
INFO 12-28 15:58:04 llm_engine.py:693] Avg past 5 seconds prompt throughput: 2367.6 tokens/s, Avg past 5 seconds real prompt throughput: 2099.9 tokens/s, Avg past 5 seconds generation throughput: 714.5 tokens/s, total prompt throughput: 69098.0 tokens/s, total real prompt throughput: 63107.0 tokens/s, total final prompt throughput: 44060.0 tokens/s, total generation throughput: 35448.0 tokens/s, avg total prompt throughput: 1980.8 tokens/s, avg total real prompt throughput: 1809.1 tokens/s, avg total final prompt throughput: 1263.0 tokens/s, avg total generation throughput: 1074.0 tokens/s, Running: 42 reqs, Swapped: 0 reqs, Waiting: 808 reqs, GPU KV cache usage: 96.8%, CPU KV cache usage: 0.0%
input_metadata = InputMetadata(prompt_lens=[36, 276], num_prompts=2, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[767], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=973, cur_paddings=0, exceeed_seq=19
input_metadata = InputMetadata(prompt_lens=[992], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[19], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=973, cur_paddings=0, exceeed_seq=24
input_metadata = InputMetadata(prompt_lens=[997], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[24], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=421, cur_paddings=93, exceeed_seq=27
input_metadata = InputMetadata(prompt_lens=[262, 355], num_prompts=2, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[27], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=406, cur_paddings=77, exceeed_seq=30
input_metadata = InputMetadata(prompt_lens=[282, 359], num_prompts=2, max_context_len=None,)
promt select exit padding exceed_paddings=270, cur_paddings=145, exceeed_seq=50
input_metadata = InputMetadata(prompt_lens=[30, 175], num_prompts=2, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[50], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=841, cur_paddings=0, exceeed_seq=9
input_metadata = InputMetadata(prompt_lens=[850], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[9], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=841, cur_paddings=0, exceeed_seq=12
input_metadata = InputMetadata(prompt_lens=[853], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=270, cur_paddings=177, exceeed_seq=43
input_metadata = InputMetadata(prompt_lens=[12, 136, 83], num_prompts=3, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[43], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[58, 6], num_prompts=2, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[53, 63, 10], num_prompts=3, max_context_len=None,)
promt select exit padding exceed_paddings=775, cur_paddings=0, exceeed_seq=131
input_metadata = InputMetadata(prompt_lens=[906], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=346, cur_paddings=232, exceeed_seq=17
input_metadata = InputMetadata(prompt_lens=[131, 8, 22], num_prompts=3, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[17], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=759, cur_paddings=255, exceeed_seq=28
input_metadata = InputMetadata(prompt_lens=[532, 277], num_prompts=2, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[28, 7], num_prompts=2, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[233, 5], num_prompts=2, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[243, 14], num_prompts=2, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[22], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[66, 60, 63, 41], num_prompts=4, max_context_len=None,)
promt select exit padding exceed_paddings=888, cur_paddings=0, exceeed_seq=80
input_metadata = InputMetadata(prompt_lens=[968], num_prompts=1, max_context_len=None,)
INFO 12-28 15:58:09 llm_engine.py:693] Avg past 5 seconds prompt throughput: 2272.4 tokens/s, Avg past 5 seconds real prompt throughput: 1902.7 tokens/s, Avg past 5 seconds generation throughput: 1076.0 tokens/s, total prompt throughput: 81096.0 tokens/s, total real prompt throughput: 73144.0 tokens/s, total final prompt throughput: 50905.0 tokens/s, total generation throughput: 40830.0 tokens/s, avg total prompt throughput: 2030.6 tokens/s, avg total real prompt throughput: 1831.4 tokens/s, avg total final prompt throughput: 1274.6 tokens/s, avg total generation throughput: 1072.8 tokens/s, Running: 35 reqs, Swapped: 0 reqs, Waiting: 786 reqs, GPU KV cache usage: 96.5%, CPU KV cache usage: 0.0%
input_metadata = InputMetadata(prompt_lens=[80, 71, 72, 50], num_prompts=4, max_context_len=None,)
promt select exit padding exceed_paddings=376, cur_paddings=230, exceeed_seq=328
input_metadata = InputMetadata(prompt_lens=[255, 25], num_prompts=2, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[328], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=505, cur_paddings=0, exceeed_seq=119
input_metadata = InputMetadata(prompt_lens=[624], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=260, cur_paddings=169, exceeed_seq=28
input_metadata = InputMetadata(prompt_lens=[119, 56, 13], num_prompts=3, max_context_len=None,)
promt select exit padding exceed_paddings=392, cur_paddings=190, exceeed_seq=16
input_metadata = InputMetadata(prompt_lens=[28, 218], num_prompts=2, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[16], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[65, 21, 35], num_prompts=3, max_context_len=None,)
promt select exit padding exceed_paddings=382, cur_paddings=180, exceeed_seq=20
input_metadata = InputMetadata(prompt_lens=[42, 222], num_prompts=2, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[20, 50], num_prompts=2, max_context_len=None,)
promt select exit padding exceed_paddings=378, cur_paddings=203, exceeed_seq=56
input_metadata = InputMetadata(prompt_lens=[231, 28], num_prompts=2, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[56], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[36], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[245, 40], num_prompts=2, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[62], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=760, cur_paddings=0, exceeed_seq=183
input_metadata = InputMetadata(prompt_lens=[943], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[183], num_prompts=1, max_context_len=None,)
INFO 12-28 15:58:14 llm_engine.py:693] Avg past 5 seconds prompt throughput: 1084.0 tokens/s, Avg past 5 seconds real prompt throughput: 816.3 tokens/s, Avg past 5 seconds generation throughput: 1205.7 tokens/s, total prompt throughput: 87443.0 tokens/s, total real prompt throughput: 78163.0 tokens/s, total final prompt throughput: 53300.0 tokens/s, total generation throughput: 46814.0 tokens/s, avg total prompt throughput: 1945.7 tokens/s, avg total real prompt throughput: 1739.2 tokens/s, avg total final prompt throughput: 1186.0 tokens/s, avg total generation throughput: 1087.1 tokens/s, Running: 31 reqs, Swapped: 0 reqs, Waiting: 769 reqs, GPU KV cache usage: 96.2%, CPU KV cache usage: 0.0%
promt select exit padding exceed_paddings=684, cur_paddings=0, exceeed_seq=123
input_metadata = InputMetadata(prompt_lens=[807], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[123], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=819, cur_paddings=0, exceeed_seq=81
input_metadata = InputMetadata(prompt_lens=[900], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=1413, cur_paddings=209, exceeed_seq=382
input_metadata = InputMetadata(prompt_lens=[81, 11, 18, 5], num_prompts=4, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[382], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=475, cur_paddings=240, exceeed_seq=47
input_metadata = InputMetadata(prompt_lens=[42, 282], num_prompts=2, max_context_len=None,)
promt select exit padding exceed_paddings=1382, cur_paddings=112, exceeed_seq=301
input_metadata = InputMetadata(prompt_lens=[47, 4, 30, 15, 27], num_prompts=5, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[301], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[304], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[308], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[105], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[335, 81], num_prompts=2, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[65, 72], num_prompts=2, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[125, 98], num_prompts=2, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[127], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[110, 136, 104, 75, 80], num_prompts=5, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[521], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=622, cur_paddings=218, exceeed_seq=445
input_metadata = InputMetadata(prompt_lens=[243, 25], num_prompts=2, max_context_len=None,)
promt select exit padding exceed_paddings=434, cur_paddings=0, exceeed_seq=11
input_metadata = InputMetadata(prompt_lens=[445], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[11, 10, 9, 7], num_prompts=4, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[12, 25, 59, 14], num_prompts=4, max_context_len=None,)
promt select exit padding exceed_paddings=347, cur_paddings=229, exceeed_seq=16
input_metadata = InputMetadata(prompt_lens=[19, 134, 20], num_prompts=3, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[16, 6, 12], num_prompts=3, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[194, 24], num_prompts=2, max_context_len=None,)
INFO 12-28 15:58:19 llm_engine.py:693] Avg past 5 seconds prompt throughput: 1710.7 tokens/s, Avg past 5 seconds real prompt throughput: 1381.4 tokens/s, Avg past 5 seconds generation throughput: 994.8 tokens/s, total prompt throughput: 96032.0 tokens/s, total real prompt throughput: 85134.0 tokens/s, total final prompt throughput: 58115.0 tokens/s, total generation throughput: 51818.0 tokens/s, avg total prompt throughput: 1921.9 tokens/s, avg total real prompt throughput: 1703.8 tokens/s, avg total final prompt throughput: 1163.1 tokens/s, avg total generation throughput: 1077.5 tokens/s, Running: 41 reqs, Swapped: 0 reqs, Waiting: 735 reqs, GPU KV cache usage: 95.6%, CPU KV cache usage: 0.0%
input_metadata = InputMetadata(prompt_lens=[599], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=721, cur_paddings=0, exceeed_seq=12
input_metadata = InputMetadata(prompt_lens=[733], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=470, cur_paddings=4, exceeed_seq=249
input_metadata = InputMetadata(prompt_lens=[12, 16], num_prompts=2, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[249, 19], num_prompts=2, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[421], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[426], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=351, cur_paddings=0, exceeed_seq=79
input_metadata = InputMetadata(prompt_lens=[430], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[79, 114, 12, 14], num_prompts=4, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[119, 17, 19], num_prompts=3, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[106, 136, 34, 35], num_prompts=4, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[752], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=746, cur_paddings=0, exceeed_seq=9
input_metadata = InputMetadata(prompt_lens=[755], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=2100, cur_paddings=105, exceeed_seq=445
input_metadata = InputMetadata(prompt_lens=[9, 13, 26, 46, 31], num_prompts=5, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[445], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=301, cur_paddings=0, exceeed_seq=310
input_metadata = InputMetadata(prompt_lens=[9], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=297, cur_paddings=0, exceeed_seq=13
input_metadata = InputMetadata(prompt_lens=[310], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[13, 35, 12, 99], num_prompts=4, max_context_len=None,)
promt select exit padding exceed_paddings=298, cur_paddings=0, exceeed_seq=21
input_metadata = InputMetadata(prompt_lens=[319], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[21, 43, 20, 105], num_prompts=4, max_context_len=None,)
promt select exit padding exceed_paddings=1044, cur_paddings=141, exceeed_seq=415
input_metadata = InputMetadata(prompt_lens=[55, 32, 114], num_prompts=3, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[415], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[417], num_prompts=1, max_context_len=None,)
INFO 12-28 15:58:24 llm_engine.py:693] Avg past 5 seconds prompt throughput: 1858.8 tokens/s, Avg past 5 seconds real prompt throughput: 1520.0 tokens/s, Avg past 5 seconds generation throughput: 1177.7 tokens/s, total prompt throughput: 105309.0 tokens/s, total real prompt throughput: 92621.0 tokens/s, total final prompt throughput: 62816.0 tokens/s, total generation throughput: 57731.0 tokens/s, avg total prompt throughput: 1915.4 tokens/s, avg total real prompt throughput: 1684.6 tokens/s, avg total final prompt throughput: 1142.5 tokens/s, avg total generation throughput: 1087.1 tokens/s, Running: 40 reqs, Swapped: 0 reqs, Waiting: 714 reqs, GPU KV cache usage: 99.7%, CPU KV cache usage: 0.0%
promt select exit padding exceed_paddings=1364, cur_paddings=212, exceeed_seq=433
input_metadata = InputMetadata(prompt_lens=[69, 89, 65, 145], num_prompts=4, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[433], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=429, cur_paddings=108, exceeed_seq=228
input_metadata = InputMetadata(prompt_lens=[441, 549], num_prompts=2, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[228, 337], num_prompts=2, max_context_len=None,)
promt select exit padding exceed_paddings=726, cur_paddings=194, exceeed_seq=19
input_metadata = InputMetadata(prompt_lens=[357, 551], num_prompts=2, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[19], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[734], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[756], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[806], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[822, 791], num_prompts=2, max_context_len=None,)
INFO 12-28 15:58:29 llm_engine.py:693] Avg past 5 seconds prompt throughput: 1279.4 tokens/s, Avg past 5 seconds real prompt throughput: 1150.9 tokens/s, Avg past 5 seconds generation throughput: 1138.0 tokens/s, total prompt throughput: 111928.0 tokens/s, total real prompt throughput: 98617.0 tokens/s, total final prompt throughput: 65234.0 tokens/s, total generation throughput: 63451.0 tokens/s, avg total prompt throughput: 1865.5 tokens/s, avg total real prompt throughput: 1643.6 tokens/s, avg total final prompt throughput: 1087.2 tokens/s, avg total generation throughput: 1091.7 tokens/s, Running: 31 reqs, Swapped: 0 reqs, Waiting: 703 reqs, GPU KV cache usage: 95.5%, CPU KV cache usage: 0.0%
promt select exit padding exceed_paddings=965, cur_paddings=0, exceeed_seq=14
input_metadata = InputMetadata(prompt_lens=[979], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[14], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=497, cur_paddings=0, exceeed_seq=88
input_metadata = InputMetadata(prompt_lens=[585], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=315, cur_paddings=213, exceeed_seq=99
input_metadata = InputMetadata(prompt_lens=[88, 101, 201], num_prompts=3, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[99, 171, 6], num_prompts=3, max_context_len=None,)
promt select exit padding exceed_paddings=344, cur_paddings=0, exceeed_seq=14
input_metadata = InputMetadata(prompt_lens=[358], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[14, 17], num_prompts=2, max_context_len=None,)
promt select exit padding exceed_paddings=268, cur_paddings=142, exceeed_seq=38
input_metadata = InputMetadata(prompt_lens=[22, 164], num_prompts=2, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[38, 11], num_prompts=2, max_context_len=None,)
promt select exit padding exceed_paddings=344, cur_paddings=0, exceeed_seq=34
input_metadata = InputMetadata(prompt_lens=[378], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[34], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=265, cur_paddings=137, exceeed_seq=43
input_metadata = InputMetadata(prompt_lens=[34, 171], num_prompts=2, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[43, 16], num_prompts=2, max_context_len=None,)
promt select exit padding exceed_paddings=288, cur_paddings=130, exceeed_seq=20
input_metadata = InputMetadata(prompt_lens=[178, 48], num_prompts=2, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[20, 108], num_prompts=2, max_context_len=None,)
promt select exit padding exceed_paddings=291, cur_paddings=131, exceeed_seq=31
input_metadata = InputMetadata(prompt_lens=[191, 60], num_prompts=2, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[31], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[67, 37, 113], num_prompts=3, max_context_len=None,)
promt select exit padding exceed_paddings=687, cur_paddings=0, exceeed_seq=175
input_metadata = InputMetadata(prompt_lens=[862], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[175, 194], num_prompts=2, max_context_len=None,)
promt select exit padding exceed_paddings=1662, cur_paddings=192, exceeed_seq=933
input_metadata = InputMetadata(prompt_lens=[198, 6], num_prompts=2, max_context_len=None,)
promt select exit padding exceed_paddings=915, cur_paddings=0, exceeed_seq=18
input_metadata = InputMetadata(prompt_lens=[933], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[18, 8, 12, 57, 9], num_prompts=5, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[62, 14], num_prompts=2, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[68, 20], num_prompts=2, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[506], num_prompts=1, max_context_len=None,)
INFO 12-28 15:58:34 llm_engine.py:693] Avg past 5 seconds prompt throughput: 2117.0 tokens/s, Avg past 5 seconds real prompt throughput: 1696.2 tokens/s, Avg past 5 seconds generation throughput: 936.3 tokens/s, total prompt throughput: 122350.0 tokens/s, total real prompt throughput: 107263.0 tokens/s, total final prompt throughput: 71253.0 tokens/s, total generation throughput: 68145.0 tokens/s, avg total prompt throughput: 1882.1 tokens/s, avg total real prompt throughput: 1650.0 tokens/s, avg total final prompt throughput: 1096.1 tokens/s, avg total generation throughput: 1079.5 tokens/s, Running: 36 reqs, Swapped: 0 reqs, Waiting: 676 reqs, GPU KV cache usage: 98.3%, CPU KV cache usage: 0.0%
input_metadata = InputMetadata(prompt_lens=[520], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[874], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=768, cur_paddings=0, exceeed_seq=112
input_metadata = InputMetadata(prompt_lens=[880], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=263, cur_paddings=163, exceeed_seq=12
input_metadata = InputMetadata(prompt_lens=[112, 9, 52], num_prompts=3, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[12, 19], num_prompts=2, max_context_len=None,)
promt select exit padding exceed_paddings=270, cur_paddings=166, exceeed_seq=23
input_metadata = InputMetadata(prompt_lens=[127, 24, 64], num_prompts=3, max_context_len=None,)
promt select exit padding exceed_paddings=1017, cur_paddings=5, exceeed_seq=534
input_metadata = InputMetadata(prompt_lens=[23, 28], num_prompts=2, max_context_len=None,)
promt select exit padding exceed_paddings=530, cur_paddings=0, exceeed_seq=4
input_metadata = InputMetadata(prompt_lens=[534], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[4], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[560], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[565], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=867, cur_paddings=0, exceeed_seq=6
input_metadata = InputMetadata(prompt_lens=[873], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[6, 10, 107], num_prompts=3, max_context_len=None,)
promt select exit padding exceed_paddings=336, cur_paddings=0, exceeed_seq=16
input_metadata = InputMetadata(prompt_lens=[352], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[16, 44, 38, 15, 8], num_prompts=5, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[925], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=576, cur_paddings=0, exceeed_seq=108
input_metadata = InputMetadata(prompt_lens=[684], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=401, cur_paddings=0, exceeed_seq=509
input_metadata = InputMetadata(prompt_lens=[108], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=492, cur_paddings=0, exceeed_seq=17
input_metadata = InputMetadata(prompt_lens=[509], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[17], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=492, cur_paddings=0, exceeed_seq=29
input_metadata = InputMetadata(prompt_lens=[521], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=337, cur_paddings=0, exceeed_seq=366
input_metadata = InputMetadata(prompt_lens=[29], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=341, cur_paddings=0, exceeed_seq=25
input_metadata = InputMetadata(prompt_lens=[366], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[25], num_prompts=1, max_context_len=None,)
INFO 12-28 15:58:39 llm_engine.py:693] Avg past 5 seconds prompt throughput: 2229.5 tokens/s, Avg past 5 seconds real prompt throughput: 2082.5 tokens/s, Avg past 5 seconds generation throughput: 1014.4 tokens/s, total prompt throughput: 132529.0 tokens/s, total real prompt throughput: 116804.0 tokens/s, total final prompt throughput: 77453.0 tokens/s, total generation throughput: 73240.0 tokens/s, avg total prompt throughput: 1892.7 tokens/s, avg total real prompt throughput: 1668.1 tokens/s, avg total final prompt throughput: 1106.1 tokens/s, avg total generation throughput: 1074.8 tokens/s, Running: 39 reqs, Swapped: 0 reqs, Waiting: 653 reqs, GPU KV cache usage: 97.5%, CPU KV cache usage: 0.0%
promt select exit padding exceed_paddings=341, cur_paddings=0, exceeed_seq=30
input_metadata = InputMetadata(prompt_lens=[371], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[30], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=494, cur_paddings=0, exceeed_seq=68
input_metadata = InputMetadata(prompt_lens=[562], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[68, 50], num_prompts=2, max_context_len=None,)
promt select exit padding exceed_paddings=411, cur_paddings=0, exceeed_seq=468
input_metadata = InputMetadata(prompt_lens=[57], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=453, cur_paddings=0, exceeed_seq=15
input_metadata = InputMetadata(prompt_lens=[468], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=359, cur_paddings=75, exceeed_seq=232
input_metadata = InputMetadata(prompt_lens=[15, 90], num_prompts=2, max_context_len=None,)
promt select exit padding exceed_paddings=322, cur_paddings=222, exceeed_seq=132
input_metadata = InputMetadata(prompt_lens=[232, 10], num_prompts=2, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[132, 54], num_prompts=2, max_context_len=None,)
promt select exit padding exceed_paddings=341, cur_paddings=0, exceeed_seq=32
input_metadata = InputMetadata(prompt_lens=[373], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[32, 26, 40, 41, 15], num_prompts=5, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[277, 53], num_prompts=2, max_context_len=None,)
promt select exit padding exceed_paddings=391, cur_paddings=0, exceeed_seq=561
input_metadata = InputMetadata(prompt_lens=[170], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[561], num_prompts=1, max_context_len=None,)
INFO 12-28 15:58:44 llm_engine.py:693] Avg past 5 seconds prompt throughput: 810.3 tokens/s, Avg past 5 seconds real prompt throughput: 669.1 tokens/s, Avg past 5 seconds generation throughput: 1148.1 tokens/s, total prompt throughput: 136388.0 tokens/s, total real prompt throughput: 119995.0 tokens/s, total final prompt throughput: 79006.0 tokens/s, total generation throughput: 79020.0 tokens/s, avg total prompt throughput: 1817.3 tokens/s, avg total real prompt throughput: 1598.9 tokens/s, avg total final prompt throughput: 1052.7 tokens/s, avg total generation throughput: 1079.9 tokens/s, Running: 28 reqs, Swapped: 0 reqs, Waiting: 650 reqs, GPU KV cache usage: 98.8%, CPU KV cache usage: 0.0%
promt select exit padding exceed_paddings=298, cur_paddings=68, exceeed_seq=289
input_metadata = InputMetadata(prompt_lens=[106, 174], num_prompts=2, max_context_len=None,)
promt select exit padding exceed_paddings=344, cur_paddings=226, exceeed_seq=171
input_metadata = InputMetadata(prompt_lens=[289, 63], num_prompts=2, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[171], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=355, cur_paddings=230, exceeed_seq=177
input_metadata = InputMetadata(prompt_lens=[302, 72], num_prompts=2, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[177], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[83, 183], num_prompts=2, max_context_len=None,)
promt select exit padding exceed_paddings=481, cur_paddings=101, exceeed_seq=381
input_metadata = InputMetadata(prompt_lens=[191, 90], num_prompts=2, max_context_len=None,)
promt select exit padding exceed_paddings=341, cur_paddings=0, exceeed_seq=40
input_metadata = InputMetadata(prompt_lens=[381], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=473, cur_paddings=48, exceeed_seq=131
input_metadata = InputMetadata(prompt_lens=[40, 32, 46, 46, 18], num_prompts=5, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[131, 25, 140, 9], num_prompts=4, max_context_len=None,)
promt select exit padding exceed_paddings=343, cur_paddings=0, exceeed_seq=64
input_metadata = InputMetadata(prompt_lens=[407], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[64], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[255], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=423, cur_paddings=115, exceeed_seq=416
input_metadata = InputMetadata(prompt_lens=[262, 147], num_prompts=2, max_context_len=None,)
promt select exit padding exceed_paddings=345, cur_paddings=0, exceeed_seq=71
input_metadata = InputMetadata(prompt_lens=[416], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=342, cur_paddings=46, exceeed_seq=145
input_metadata = InputMetadata(prompt_lens=[71, 67, 64, 36], num_prompts=4, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[145], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[37, 148, 16], num_prompts=3, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[97, 91, 61], num_prompts=3, max_context_len=None,)
INFO 12-28 15:58:49 llm_engine.py:693] Avg past 5 seconds prompt throughput: 1300.1 tokens/s, Avg past 5 seconds real prompt throughput: 1006.3 tokens/s, Avg past 5 seconds generation throughput: 970.3 tokens/s, total prompt throughput: 143285.0 tokens/s, total real prompt throughput: 125460.0 tokens/s, total final prompt throughput: 79311.0 tokens/s, total generation throughput: 83892.0 tokens/s, avg total prompt throughput: 1789.5 tokens/s, avg total real prompt throughput: 1566.9 tokens/s, avg total final prompt throughput: 990.5 tokens/s, avg total generation throughput: 1072.9 tokens/s, Running: 28 reqs, Swapped: 0 reqs, Waiting: 639 reqs, GPU KV cache usage: 99.8%, CPU KV cache usage: 0.0%
promt select exit padding exceed_paddings=272, cur_paddings=171, exceeed_seq=100
input_metadata = InputMetadata(prompt_lens=[201, 121, 110], num_prompts=3, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[100, 67], num_prompts=2, max_context_len=None,)
promt select exit padding exceed_paddings=343, cur_paddings=129, exceeed_seq=141
input_metadata = InputMetadata(prompt_lens=[355, 226], num_prompts=2, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[141, 124, 109, 75, 163], num_prompts=5, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[169, 53], num_prompts=2, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[112, 187, 63], num_prompts=3, max_context_len=None,)
promt select exit padding exceed_paddings=342, cur_paddings=168, exceeed_seq=26
input_metadata = InputMetadata(prompt_lens=[200, 72, 160], num_prompts=3, max_context_len=None,)
promt select exit padding exceed_paddings=554, cur_paddings=0, exceeed_seq=580
input_metadata = InputMetadata(prompt_lens=[26], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=572, cur_paddings=0, exceeed_seq=8
input_metadata = InputMetadata(prompt_lens=[580], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[8], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=572, cur_paddings=0, exceeed_seq=15
input_metadata = InputMetadata(prompt_lens=[587], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[15], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=317, cur_paddings=153, exceeed_seq=4
input_metadata = InputMetadata(prompt_lens=[168, 15], num_prompts=2, max_context_len=None,)
promt select exit padding exceed_paddings=257, cur_paddings=7, exceeed_seq=136
input_metadata = InputMetadata(prompt_lens=[4, 11], num_prompts=2, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[136, 13], num_prompts=2, max_context_len=None,)
promt select exit padding exceed_paddings=476, cur_paddings=124, exceeed_seq=322
input_metadata = InputMetadata(prompt_lens=[146, 22], num_prompts=2, max_context_len=None,)
promt select exit padding exceed_paddings=432, cur_paddings=70, exceeed_seq=30
input_metadata = InputMetadata(prompt_lens=[322, 392], num_prompts=2, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[30, 15, 19], num_prompts=3, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[178, 178], num_prompts=2, max_context_len=None,)
INFO 12-28 15:58:54 llm_engine.py:693] Avg past 5 seconds prompt throughput: 1515.0 tokens/s, Avg past 5 seconds real prompt throughput: 1177.8 tokens/s, Avg past 5 seconds generation throughput: 855.6 tokens/s, total prompt throughput: 150415.0 tokens/s, total real prompt throughput: 131026.0 tokens/s, total final prompt throughput: 81024.0 tokens/s, total generation throughput: 88185.0 tokens/s, avg total prompt throughput: 1767.9 tokens/s, avg total real prompt throughput: 1540.0 tokens/s, avg total final prompt throughput: 952.3 tokens/s, avg total generation throughput: 1059.9 tokens/s, Running: 35 reqs, Swapped: 0 reqs, Waiting: 619 reqs, GPU KV cache usage: 99.2%, CPU KV cache usage: 0.0%
promt select exit padding exceed_paddings=431, cur_paddings=0, exceeed_seq=14
input_metadata = InputMetadata(prompt_lens=[445], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[14, 66, 12], num_prompts=3, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[461], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=486, cur_paddings=0, exceeed_seq=53
input_metadata = InputMetadata(prompt_lens=[539], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[53, 15], num_prompts=2, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[554], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[66, 27], num_prompts=2, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[915], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=497, cur_paddings=0, exceeed_seq=110
input_metadata = InputMetadata(prompt_lens=[607], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[110, 69], num_prompts=2, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[77], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=876, cur_paddings=0, exceeed_seq=44
input_metadata = InputMetadata(prompt_lens=[920], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=642, cur_paddings=0, exceeed_seq=686
input_metadata = InputMetadata(prompt_lens=[44], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=675, cur_paddings=0, exceeed_seq=11
input_metadata = InputMetadata(prompt_lens=[686], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[11], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[48, 17], num_prompts=2, max_context_len=None,)
promt select exit padding exceed_paddings=927, cur_paddings=0, exceeed_seq=38
input_metadata = InputMetadata(prompt_lens=[965], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=420, cur_paddings=0, exceeed_seq=458
input_metadata = InputMetadata(prompt_lens=[38], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[458], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[598], num_prompts=1, max_context_len=None,)
INFO 12-28 15:58:59 llm_engine.py:693] Avg past 5 seconds prompt throughput: 1519.6 tokens/s, Avg past 5 seconds real prompt throughput: 1467.8 tokens/s, Avg past 5 seconds generation throughput: 1025.6 tokens/s, total prompt throughput: 158243.0 tokens/s, total real prompt throughput: 138599.0 tokens/s, total final prompt throughput: 86167.0 tokens/s, total generation throughput: 93343.0 tokens/s, avg total prompt throughput: 1756.2 tokens/s, avg total real prompt throughput: 1538.2 tokens/s, avg total final prompt throughput: 956.3 tokens/s, avg total generation throughput: 1058.0 tokens/s, Running: 34 reqs, Swapped: 0 reqs, Waiting: 601 reqs, GPU KV cache usage: 97.2%, CPU KV cache usage: 0.0%
promt select exit padding exceed_paddings=655, cur_paddings=0, exceeed_seq=152
input_metadata = InputMetadata(prompt_lens=[807], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=261, cur_paddings=142, exceeed_seq=33
input_metadata = InputMetadata(prompt_lens=[152, 10], num_prompts=2, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[33], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=662, cur_paddings=158, exceeed_seq=14
input_metadata = InputMetadata(prompt_lens=[518, 360], num_prompts=2, max_context_len=None,)
promt select exit padding exceed_paddings=296, cur_paddings=0, exceeed_seq=310
input_metadata = InputMetadata(prompt_lens=[14], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=261, cur_paddings=215, exceeed_seq=333
input_metadata = InputMetadata(prompt_lens=[310, 95], num_prompts=2, max_context_len=None,)
promt select exit padding exceed_paddings=321, cur_paddings=0, exceeed_seq=12
input_metadata = InputMetadata(prompt_lens=[333], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[12], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=321, cur_paddings=0, exceeed_seq=18
input_metadata = InputMetadata(prompt_lens=[339], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=443, cur_paddings=0, exceeed_seq=461
input_metadata = InputMetadata(prompt_lens=[18], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[461], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=312, cur_paddings=0, exceeed_seq=11
input_metadata = InputMetadata(prompt_lens=[323], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[11], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=277, cur_paddings=127, exceeed_seq=18
input_metadata = InputMetadata(prompt_lens=[168, 41], num_prompts=2, max_context_len=None,)
promt select exit padding exceed_paddings=324, cur_paddings=0, exceeed_seq=342
input_metadata = InputMetadata(prompt_lens=[18], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=328, cur_paddings=0, exceeed_seq=14
input_metadata = InputMetadata(prompt_lens=[342], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=606, cur_paddings=66, exceeed_seq=350
input_metadata = InputMetadata(prompt_lens=[14, 80], num_prompts=2, max_context_len=None,)
promt select exit padding exceed_paddings=342, cur_paddings=0, exceeed_seq=8
input_metadata = InputMetadata(prompt_lens=[350], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[8, 13], num_prompts=2, max_context_len=None,)
promt select exit padding exceed_paddings=697, cur_paddings=0, exceeed_seq=9
input_metadata = InputMetadata(prompt_lens=[706], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=328, cur_paddings=175, exceeed_seq=31
input_metadata = InputMetadata(prompt_lens=[9, 184], num_prompts=2, max_context_len=None,)
promt select exit padding exceed_paddings=336, cur_paddings=0, exceeed_seq=367
input_metadata = InputMetadata(prompt_lens=[31], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[367], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[917], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=353, cur_paddings=189, exceeed_seq=314
input_metadata = InputMetadata(prompt_lens=[232, 43], num_prompts=2, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[314, 58], num_prompts=2, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[627, 765], num_prompts=2, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[768], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=503, cur_paddings=208, exceeed_seq=14
input_metadata = InputMetadata(prompt_lens=[309, 101], num_prompts=2, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[14, 25, 27, 19], num_prompts=4, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[122], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=385, cur_paddings=21, exceeed_seq=127
input_metadata = InputMetadata(prompt_lens=[24, 35, 36, 28], num_prompts=4, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[127], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=991, cur_paddings=235, exceeed_seq=936
input_metadata = InputMetadata(prompt_lens=[558, 323], num_prompts=2, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[936], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=743, cur_paddings=161, exceeed_seq=471
input_metadata = InputMetadata(prompt_lens=[180, 19], num_prompts=2, max_context_len=None,)
promt select exit padding exceed_paddings=435, cur_paddings=0, exceeed_seq=36
input_metadata = InputMetadata(prompt_lens=[471], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[36, 13], num_prompts=2, max_context_len=None,)
promt select exit padding exceed_paddings=473, cur_paddings=83, exceeed_seq=294
input_metadata = InputMetadata(prompt_lens=[16, 99], num_prompts=2, max_context_len=None,)
promt select exit padding exceed_paddings=265, cur_paddings=0, exceeed_seq=29
input_metadata = InputMetadata(prompt_lens=[294], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=1864, cur_paddings=104, exceeed_seq=256
input_metadata = InputMetadata(prompt_lens=[29, 35, 15, 11, 33, 17, 8, 36], num_prompts=8, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[256], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=482, cur_paddings=0, exceeed_seq=56
input_metadata = InputMetadata(prompt_lens=[538], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[56, 22], num_prompts=2, max_context_len=None,)
promt select exit padding exceed_paddings=483, cur_paddings=0, exceeed_seq=64
input_metadata = InputMetadata(prompt_lens=[547], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[64, 30], num_prompts=2, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[554], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=344, cur_paddings=0, exceeed_seq=94
input_metadata = InputMetadata(prompt_lens=[438], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[94], num_prompts=1, max_context_len=None,)
INFO 12-28 15:59:04 llm_engine.py:693] Avg past 5 seconds prompt throughput: 4023.9 tokens/s, Avg past 5 seconds real prompt throughput: 3509.4 tokens/s, Avg past 5 seconds generation throughput: 943.6 tokens/s, total prompt throughput: 177590.0 tokens/s, total real prompt throughput: 155549.0 tokens/s, total final prompt throughput: 101085.0 tokens/s, total generation throughput: 98092.0 tokens/s, avg total prompt throughput: 1866.8 tokens/s, avg total real prompt throughput: 1635.2 tokens/s, avg total final prompt throughput: 1062.6 tokens/s, avg total generation throughput: 1051.9 tokens/s, Running: 61 reqs, Swapped: 0 reqs, Waiting: 534 reqs, GPU KV cache usage: 97.8%, CPU KV cache usage: 0.0%
promt select exit padding exceed_paddings=347, cur_paddings=0, exceeed_seq=101
input_metadata = InputMetadata(prompt_lens=[448], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=515, cur_paddings=0, exceeed_seq=616
input_metadata = InputMetadata(prompt_lens=[101], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=598, cur_paddings=0, exceeed_seq=18
input_metadata = InputMetadata(prompt_lens=[616], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[18, 146], num_prompts=2, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[271], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=598, cur_paddings=0, exceeed_seq=34
input_metadata = InputMetadata(prompt_lens=[632], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[34, 158], num_prompts=2, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[275], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=320, cur_paddings=87, exceeed_seq=45
input_metadata = InputMetadata(prompt_lens=[278, 191], num_prompts=2, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[45, 26, 41, 24, 21, 23, 50], num_prompts=7, max_context_len=None,)
promt select exit padding exceed_paddings=966, cur_paddings=0, exceeed_seq=40
input_metadata = InputMetadata(prompt_lens=[1006], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=502, cur_paddings=66, exceeed_seq=159
input_metadata = InputMetadata(prompt_lens=[40, 21, 50, 23], num_prompts=4, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[159], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=968, cur_paddings=0, exceeed_seq=48
input_metadata = InputMetadata(prompt_lens=[1016], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[48, 28, 56, 28], num_prompts=4, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[52, 31, 58, 30], num_prompts=4, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[87, 87, 112], num_prompts=3, max_context_len=None,)
INFO 12-28 15:59:09 llm_engine.py:693] Avg past 5 seconds prompt throughput: 1547.7 tokens/s, Avg past 5 seconds real prompt throughput: 1397.4 tokens/s, Avg past 5 seconds generation throughput: 1570.5 tokens/s, total prompt throughput: 184378.0 tokens/s, total real prompt throughput: 161687.0 tokens/s, total final prompt throughput: 103950.0 tokens/s, total generation throughput: 105985.0 tokens/s, avg total prompt throughput: 1841.1 tokens/s, avg total real prompt throughput: 1614.5 tokens/s, avg total final prompt throughput: 1038.0 tokens/s, avg total generation throughput: 1078.5 tokens/s, Running: 45 reqs, Swapped: 0 reqs, Waiting: 524 reqs, GPU KV cache usage: 99.2%, CPU KV cache usage: 0.0%
input_metadata = InputMetadata(prompt_lens=[128, 121], num_prompts=2, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[135], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[126], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[117], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[123], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[140], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[152], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[152], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[157], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[163], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[236], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[226, 203, 185], num_prompts=3, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[191], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[201], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[207, 167], num_prompts=2, max_context_len=None,)
promt select exit padding exceed_paddings=969, cur_paddings=0, exceeed_seq=62
input_metadata = InputMetadata(prompt_lens=[1031], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[62, 40], num_prompts=2, max_context_len=None,)
promt select exit padding exceed_paddings=971, cur_paddings=0, exceeed_seq=70
input_metadata = InputMetadata(prompt_lens=[1041], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[70, 47], num_prompts=2, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[66, 37, 161], num_prompts=3, max_context_len=None,)
INFO 12-28 15:59:14 llm_engine.py:693] Avg past 5 seconds prompt throughput: 1172.0 tokens/s, Avg past 5 seconds real prompt throughput: 1139.2 tokens/s, Avg past 5 seconds generation throughput: 1111.7 tokens/s, total prompt throughput: 190291.0 tokens/s, total real prompt throughput: 167394.0 tokens/s, total final prompt throughput: 103950.0 tokens/s, total generation throughput: 111572.0 tokens/s, avg total prompt throughput: 1809.6 tokens/s, avg total real prompt throughput: 1591.8 tokens/s, avg total final prompt throughput: 988.5 tokens/s, avg total generation throughput: 1080.3 tokens/s, Running: 34 reqs, Swapped: 0 reqs, Waiting: 517 reqs, GPU KV cache usage: 99.7%, CPU KV cache usage: 0.0%
input_metadata = InputMetadata(prompt_lens=[253], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[1062], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=394, cur_paddings=74, exceeed_seq=168
input_metadata = InputMetadata(prompt_lens=[88, 63, 79, 48], num_prompts=4, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[168], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=981, cur_paddings=0, exceeed_seq=110
input_metadata = InputMetadata(prompt_lens=[1091], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[110, 93], num_prompts=2, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[61, 175], num_prompts=2, max_context_len=None,)
promt select exit padding exceed_paddings=279, cur_paddings=0, exceeed_seq=94
input_metadata = InputMetadata(prompt_lens=[373], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[94, 47], num_prompts=2, max_context_len=None,)
promt select exit padding exceed_paddings=285, cur_paddings=0, exceeed_seq=100
input_metadata = InputMetadata(prompt_lens=[385], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[100], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=923, cur_paddings=25, exceeed_seq=500
input_metadata = InputMetadata(prompt_lens=[51, 26], num_prompts=2, max_context_len=None,)
promt select exit padding exceed_paddings=484, cur_paddings=0, exceeed_seq=16
input_metadata = InputMetadata(prompt_lens=[500], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[16], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=486, cur_paddings=0, exceeed_seq=27
input_metadata = InputMetadata(prompt_lens=[513], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[27], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=554, cur_paddings=0, exceeed_seq=332
input_metadata = InputMetadata(prompt_lens=[886], num_prompts=1, max_context_len=None,)
INFO 12-28 15:59:19 llm_engine.py:693] Avg past 5 seconds prompt throughput: 1692.1 tokens/s, Avg past 5 seconds real prompt throughput: 1609.9 tokens/s, Avg past 5 seconds generation throughput: 929.1 tokens/s, total prompt throughput: 196474.0 tokens/s, total real prompt throughput: 173081.0 tokens/s, total final prompt throughput: 105006.0 tokens/s, total generation throughput: 116300.0 tokens/s, avg total prompt throughput: 1782.5 tokens/s, avg total real prompt throughput: 1570.3 tokens/s, avg total final prompt throughput: 952.7 tokens/s, avg total generation throughput: 1073.4 tokens/s, Running: 28 reqs, Swapped: 0 reqs, Waiting: 509 reqs, GPU KV cache usage: 96.2%, CPU KV cache usage: 0.0%
input_metadata = InputMetadata(prompt_lens=[332], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[304], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[668], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[683], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=455, cur_paddings=132, exceeed_seq=19
input_metadata = InputMetadata(prompt_lens=[342, 210], num_prompts=2, max_context_len=None,)
promt select exit padding exceed_paddings=572, cur_paddings=8, exceeed_seq=301
input_metadata = InputMetadata(prompt_lens=[19, 11], num_prompts=2, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[301], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[245], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=816, cur_paddings=0, exceeed_seq=18
input_metadata = InputMetadata(prompt_lens=[834], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[18], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=422, cur_paddings=180, exceeed_seq=11
input_metadata = InputMetadata(prompt_lens=[253, 73], num_prompts=2, max_context_len=None,)
promt select exit padding exceed_paddings=446, cur_paddings=0, exceeed_seq=457
input_metadata = InputMetadata(prompt_lens=[11], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=418, cur_paddings=0, exceeed_seq=39
input_metadata = InputMetadata(prompt_lens=[457], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[39, 88], num_prompts=2, max_context_len=None,)
promt select exit padding exceed_paddings=499, cur_paddings=31, exceeed_seq=291
input_metadata = InputMetadata(prompt_lens=[26, 57], num_prompts=2, max_context_len=None,)
promt select exit padding exceed_paddings=264, cur_paddings=0, exceeed_seq=27
input_metadata = InputMetadata(prompt_lens=[291], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[27, 22], num_prompts=2, max_context_len=None,)
promt select exit padding exceed_paddings=372, cur_paddings=0, exceeed_seq=8
input_metadata = InputMetadata(prompt_lens=[380], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[8, 15], num_prompts=2, max_context_len=None,)
promt select exit padding exceed_paddings=373, cur_paddings=0, exceeed_seq=13
input_metadata = InputMetadata(prompt_lens=[386], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[13, 20], num_prompts=2, max_context_len=None,)
promt select exit padding exceed_paddings=386, cur_paddings=46, exceeed_seq=8
input_metadata = InputMetadata(prompt_lens=[348, 302], num_prompts=2, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[8], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=295, cur_paddings=0, exceeed_seq=13
input_metadata = InputMetadata(prompt_lens=[308], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[13, 13], num_prompts=2, max_context_len=None,)
promt select exit padding exceed_paddings=496, cur_paddings=0, exceeed_seq=40
input_metadata = InputMetadata(prompt_lens=[536], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[40, 167], num_prompts=2, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[170, 58], num_prompts=2, max_context_len=None,)
promt select exit padding exceed_paddings=388, cur_paddings=0, exceeed_seq=44
input_metadata = InputMetadata(prompt_lens=[432], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[44], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[458], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[463], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=287, cur_paddings=148, exceeed_seq=29
input_metadata = InputMetadata(prompt_lens=[168, 20], num_prompts=2, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[29, 15, 8, 32], num_prompts=4, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[37], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[42, 27, 19, 40], num_prompts=4, max_context_len=None,)
INFO 12-28 15:59:24 llm_engine.py:693] Avg past 5 seconds prompt throughput: 2149.1 tokens/s, Avg past 5 seconds real prompt throughput: 1969.1 tokens/s, Avg past 5 seconds generation throughput: 990.1 tokens/s, total prompt throughput: 208058.0 tokens/s, total real prompt throughput: 183769.0 tokens/s, total final prompt throughput: 113601.0 tokens/s, total generation throughput: 121231.0 tokens/s, avg total prompt throughput: 1805.4 tokens/s, avg total real prompt throughput: 1594.6 tokens/s, avg total final prompt throughput: 985.7 tokens/s, avg total generation throughput: 1069.4 tokens/s, Running: 41 reqs, Swapped: 0 reqs, Waiting: 468 reqs, GPU KV cache usage: 99.7%, CPU KV cache usage: 0.0%
input_metadata = InputMetadata(prompt_lens=[53, 43, 63], num_prompts=3, max_context_len=None,)
promt select exit padding exceed_paddings=860, cur_paddings=0, exceeed_seq=156
input_metadata = InputMetadata(prompt_lens=[1016], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[156], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=866, cur_paddings=0, exceeed_seq=160
input_metadata = InputMetadata(prompt_lens=[1026], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[160, 39, 41], num_prompts=3, max_context_len=None,)
promt select exit padding exceed_paddings=772, cur_paddings=254, exceeed_seq=541
input_metadata = InputMetadata(prompt_lens=[282, 28], num_prompts=2, max_context_len=None,)
promt select exit padding exceed_paddings=529, cur_paddings=0, exceeed_seq=12
input_metadata = InputMetadata(prompt_lens=[541], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[12], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=529, cur_paddings=0, exceeed_seq=18
input_metadata = InputMetadata(prompt_lens=[547], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[18], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=365, cur_paddings=251, exceeed_seq=320
input_metadata = InputMetadata(prompt_lens=[263, 12], num_prompts=2, max_context_len=None,)
promt select exit padding exceed_paddings=271, cur_paddings=0, exceeed_seq=49
input_metadata = InputMetadata(prompt_lens=[320], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=259, cur_paddings=31, exceeed_seq=194
input_metadata = InputMetadata(prompt_lens=[49, 80], num_prompts=2, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[194, 96], num_prompts=2, max_context_len=None,)
promt select exit padding exceed_paddings=283, cur_paddings=0, exceeed_seq=384
input_metadata = InputMetadata(prompt_lens=[101], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=382, cur_paddings=13, exceeed_seq=28
input_metadata = InputMetadata(prompt_lens=[384, 397], num_prompts=2, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[28], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[976], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=316, cur_paddings=0, exceeed_seq=97
input_metadata = InputMetadata(prompt_lens=[413], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[97, 12], num_prompts=2, max_context_len=None,)
promt select exit padding exceed_paddings=531, cur_paddings=0, exceeed_seq=62
input_metadata = InputMetadata(prompt_lens=[593], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[62], num_prompts=1, max_context_len=None,)
INFO 12-28 15:59:29 llm_engine.py:693] Avg past 5 seconds prompt throughput: 1848.2 tokens/s, Avg past 5 seconds real prompt throughput: 1643.4 tokens/s, Avg past 5 seconds generation throughput: 1131.5 tokens/s, total prompt throughput: 217268.0 tokens/s, total real prompt throughput: 191937.0 tokens/s, total final prompt throughput: 119630.0 tokens/s, total generation throughput: 126900.0 tokens/s, avg total prompt throughput: 1806.8 tokens/s, avg total real prompt throughput: 1596.2 tokens/s, avg total final prompt throughput: 994.9 tokens/s, avg total generation throughput: 1072.1 tokens/s, Running: 40 reqs, Swapped: 0 reqs, Waiting: 443 reqs, GPU KV cache usage: 97.8%, CPU KV cache usage: 0.0%
promt select exit padding exceed_paddings=533, cur_paddings=0, exceeed_seq=80
input_metadata = InputMetadata(prompt_lens=[613], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[80], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=526, cur_paddings=0, exceeed_seq=609
input_metadata = InputMetadata(prompt_lens=[83], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=407, cur_paddings=0, exceeed_seq=202
input_metadata = InputMetadata(prompt_lens=[609], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[202, 26], num_prompts=2, max_context_len=None,)
promt select exit padding exceed_paddings=412, cur_paddings=0, exceeed_seq=9
input_metadata = InputMetadata(prompt_lens=[421], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[9], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[338], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[352], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[358], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[371], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=874, cur_paddings=0, exceeed_seq=82
input_metadata = InputMetadata(prompt_lens=[956], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[82, 7], num_prompts=2, max_context_len=None,)
promt select exit padding exceed_paddings=877, cur_paddings=0, exceeed_seq=93
input_metadata = InputMetadata(prompt_lens=[970], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[93, 18], num_prompts=2, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[439], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[8], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=647, cur_paddings=0, exceeed_seq=18
input_metadata = InputMetadata(prompt_lens=[665], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[18, 14, 17, 62], num_prompts=4, max_context_len=None,)
promt select exit padding exceed_paddings=282, cur_paddings=0, exceeed_seq=131
input_metadata = InputMetadata(prompt_lens=[413], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[131, 26], num_prompts=2, max_context_len=None,)
promt select exit padding exceed_paddings=311, cur_paddings=0, exceeed_seq=66
input_metadata = InputMetadata(prompt_lens=[377], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=564, cur_paddings=184, exceeed_seq=142
input_metadata = InputMetadata(prompt_lens=[66, 27, 15, 22, 16], num_prompts=5, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[142], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[155], num_prompts=1, max_context_len=None,)
INFO 12-28 15:59:34 llm_engine.py:693] Avg past 5 seconds prompt throughput: 1963.0 tokens/s, Avg past 5 seconds real prompt throughput: 1795.2 tokens/s, Avg past 5 seconds generation throughput: 1070.3 tokens/s, total prompt throughput: 226128.0 tokens/s, total real prompt throughput: 200045.0 tokens/s, total final prompt throughput: 124800.0 tokens/s, total generation throughput: 132282.0 tokens/s, avg total prompt throughput: 1805.2 tokens/s, avg total real prompt throughput: 1596.9 tokens/s, avg total final prompt throughput: 996.3 tokens/s, avg total generation throughput: 1072.1 tokens/s, Running: 44 reqs, Swapped: 0 reqs, Waiting: 417 reqs, GPU KV cache usage: 96.8%, CPU KV cache usage: 0.0%
input_metadata = InputMetadata(prompt_lens=[773], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[487], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[730], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[668], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=968, cur_paddings=0, exceeed_seq=55
input_metadata = InputMetadata(prompt_lens=[1023], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[55], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=503, cur_paddings=0, exceeed_seq=14
input_metadata = InputMetadata(prompt_lens=[517], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[14], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=590, cur_paddings=0, exceeed_seq=37
input_metadata = InputMetadata(prompt_lens=[627], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[37], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=432, cur_paddings=0, exceeed_seq=20
input_metadata = InputMetadata(prompt_lens=[452], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=266, cur_paddings=232, exceeed_seq=109
input_metadata = InputMetadata(prompt_lens=[20, 34, 143], num_prompts=3, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[109, 167], num_prompts=2, max_context_len=None,)
promt select exit padding exceed_paddings=864, cur_paddings=0, exceeed_seq=19
input_metadata = InputMetadata(prompt_lens=[883], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[19], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[29], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[788], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=659, cur_paddings=0, exceeed_seq=14
input_metadata = InputMetadata(prompt_lens=[673], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[14], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=710, cur_paddings=0, exceeed_seq=13
input_metadata = InputMetadata(prompt_lens=[723], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[13], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=710, cur_paddings=0, exceeed_seq=18
input_metadata = InputMetadata(prompt_lens=[728], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[18], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[22, 243], num_prompts=2, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[247], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[397, 320], num_prompts=2, max_context_len=None,)
promt select exit padding exceed_paddings=480, cur_paddings=87, exceeed_seq=220
input_metadata = InputMetadata(prompt_lens=[76, 15, 89], num_prompts=3, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[220, 10], num_prompts=2, max_context_len=None,)
INFO 12-28 15:59:39 llm_engine.py:693] Avg past 5 seconds prompt throughput: 2521.6 tokens/s, Avg past 5 seconds real prompt throughput: 2377.7 tokens/s, Avg past 5 seconds generation throughput: 1045.4 tokens/s, total prompt throughput: 238111.0 tokens/s, total real prompt throughput: 211353.0 tokens/s, total final prompt throughput: 134909.0 tokens/s, total generation throughput: 137524.0 tokens/s, avg total prompt throughput: 1827.9 tokens/s, avg total real prompt throughput: 1622.4 tokens/s, avg total final prompt throughput: 1035.6 tokens/s, avg total generation throughput: 1071.1 tokens/s, Running: 45 reqs, Swapped: 0 reqs, Waiting: 386 reqs, GPU KV cache usage: 99.5%, CPU KV cache usage: 0.0%
input_metadata = InputMetadata(prompt_lens=[228, 18], num_prompts=2, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[437], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[116, 97], num_prompts=2, max_context_len=None,)
promt select exit padding exceed_paddings=332, cur_paddings=0, exceeed_seq=111
input_metadata = InputMetadata(prompt_lens=[443], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[111], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[114, 50, 120], num_prompts=3, max_context_len=None,)
promt select exit padding exceed_paddings=329, cur_paddings=117, exceeed_seq=30
input_metadata = InputMetadata(prompt_lens=[125, 242], num_prompts=2, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[30], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[252, 38], num_prompts=2, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[272, 57], num_prompts=2, max_context_len=None,)
promt select exit padding exceed_paddings=772, cur_paddings=127, exceeed_seq=41
input_metadata = InputMetadata(prompt_lens=[686, 559], num_prompts=2, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[41], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[460], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=360, cur_paddings=0, exceeed_seq=85
input_metadata = InputMetadata(prompt_lens=[445], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[85, 109], num_prompts=2, max_context_len=None,)
INFO 12-28 15:59:44 llm_engine.py:693] Avg past 5 seconds prompt throughput: 1242.0 tokens/s, Avg past 5 seconds real prompt throughput: 1036.8 tokens/s, Avg past 5 seconds generation throughput: 1120.0 tokens/s, total prompt throughput: 244470.0 tokens/s, total real prompt throughput: 216524.0 tokens/s, total final prompt throughput: 137330.0 tokens/s, total generation throughput: 143151.0 tokens/s, avg total prompt throughput: 1807.1 tokens/s, avg total real prompt throughput: 1600.5 tokens/s, avg total final prompt throughput: 1015.1 tokens/s, avg total generation throughput: 1073.1 tokens/s, Running: 34 reqs, Swapped: 0 reqs, Waiting: 381 reqs, GPU KV cache usage: 99.6%, CPU KV cache usage: 0.0%
promt select exit padding exceed_paddings=365, cur_paddings=0, exceeed_seq=91
input_metadata = InputMetadata(prompt_lens=[456], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[91, 113], num_prompts=2, max_context_len=None,)
promt select exit padding exceed_paddings=447, cur_paddings=0, exceeed_seq=18
input_metadata = InputMetadata(prompt_lens=[465], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[18], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=424, cur_paddings=0, exceeed_seq=20
input_metadata = InputMetadata(prompt_lens=[444], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[20, 9, 10], num_prompts=3, max_context_len=None,)
promt select exit padding exceed_paddings=990, cur_paddings=0, exceeed_seq=17
input_metadata = InputMetadata(prompt_lens=[1007], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[17, 34, 106], num_prompts=3, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[109, 181], num_prompts=2, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[234, 89], num_prompts=2, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[746], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=827, cur_paddings=0, exceeed_seq=12
input_metadata = InputMetadata(prompt_lens=[839], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=424, cur_paddings=212, exceeed_seq=12
input_metadata = InputMetadata(prompt_lens=[12, 224], num_prompts=2, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[12, 59, 5], num_prompts=3, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[604], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[498], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=491, cur_paddings=0, exceeed_seq=19
input_metadata = InputMetadata(prompt_lens=[510], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=282, cur_paddings=0, exceeed_seq=301
input_metadata = InputMetadata(prompt_lens=[19], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=260, cur_paddings=0, exceeed_seq=41
input_metadata = InputMetadata(prompt_lens=[301], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[41, 15], num_prompts=2, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[504], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[506], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=635, cur_paddings=0, exceeed_seq=29
input_metadata = InputMetadata(prompt_lens=[664], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[29, 14, 21, 103], num_prompts=4, max_context_len=None,)
promt select exit padding exceed_paddings=781, cur_paddings=0, exceeed_seq=16
input_metadata = InputMetadata(prompt_lens=[797], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[16, 51], num_prompts=2, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[596], num_prompts=1, max_context_len=None,)
INFO 12-28 15:59:49 llm_engine.py:693] Avg past 5 seconds prompt throughput: 2291.2 tokens/s, Avg past 5 seconds real prompt throughput: 2075.2 tokens/s, Avg past 5 seconds generation throughput: 1006.2 tokens/s, total prompt throughput: 255721.0 tokens/s, total real prompt throughput: 226711.0 tokens/s, total final prompt throughput: 146242.0 tokens/s, total generation throughput: 148192.0 tokens/s, avg total prompt throughput: 1822.9 tokens/s, avg total real prompt throughput: 1616.1 tokens/s, avg total final prompt throughput: 1042.5 tokens/s, avg total generation throughput: 1070.7 tokens/s, Running: 40 reqs, Swapped: 0 reqs, Waiting: 342 reqs, GPU KV cache usage: 95.0%, CPU KV cache usage: 0.0%
promt select exit padding exceed_paddings=853, cur_paddings=0, exceeed_seq=84
input_metadata = InputMetadata(prompt_lens=[937], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[84], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=782, cur_paddings=0, exceeed_seq=77
input_metadata = InputMetadata(prompt_lens=[859], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[77], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=786, cur_paddings=0, exceeed_seq=85
input_metadata = InputMetadata(prompt_lens=[871], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[85], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=791, cur_paddings=0, exceeed_seq=90
input_metadata = InputMetadata(prompt_lens=[881], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[90, 103], num_prompts=2, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[103], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=798, cur_paddings=0, exceeed_seq=111
input_metadata = InputMetadata(prompt_lens=[909], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[111], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[111], num_prompts=1, max_context_len=None,)
INFO 12-28 15:59:54 llm_engine.py:693] Avg past 5 seconds prompt throughput: 1076.1 tokens/s, Avg past 5 seconds real prompt throughput: 1073.4 tokens/s, Avg past 5 seconds generation throughput: 1111.3 tokens/s, total prompt throughput: 261440.0 tokens/s, total real prompt throughput: 232417.0 tokens/s, total final prompt throughput: 147859.0 tokens/s, total generation throughput: 153782.0 tokens/s, avg total prompt throughput: 1799.2 tokens/s, avg total real prompt throughput: 1599.5 tokens/s, avg total final prompt throughput: 1017.5 tokens/s, avg total generation throughput: 1072.2 tokens/s, Running: 29 reqs, Swapped: 0 reqs, Waiting: 342 reqs, GPU KV cache usage: 96.5%, CPU KV cache usage: 0.0%
promt select exit padding exceed_paddings=856, cur_paddings=0, exceeed_seq=93
input_metadata = InputMetadata(prompt_lens=[949], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=396, cur_paddings=0, exceeed_seq=489
input_metadata = InputMetadata(prompt_lens=[93], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=481, cur_paddings=0, exceeed_seq=8
input_metadata = InputMetadata(prompt_lens=[489], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[8], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=311, cur_paddings=0, exceeed_seq=14
input_metadata = InputMetadata(prompt_lens=[325], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=509, cur_paddings=0, exceeed_seq=523
input_metadata = InputMetadata(prompt_lens=[14], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[523], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[535], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[546], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[556], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=417, cur_paddings=0, exceeed_seq=22
input_metadata = InputMetadata(prompt_lens=[439], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[22], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=418, cur_paddings=0, exceeed_seq=49
input_metadata = InputMetadata(prompt_lens=[467], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=419, cur_paddings=0, exceeed_seq=468
input_metadata = InputMetadata(prompt_lens=[49], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[468], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[121, 189, 21], num_prompts=3, max_context_len=None,)
promt select exit padding exceed_paddings=342, cur_paddings=0, exceeed_seq=34
input_metadata = InputMetadata(prompt_lens=[376], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[34], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=751, cur_paddings=0, exceeed_seq=11
input_metadata = InputMetadata(prompt_lens=[762], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[11], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=752, cur_paddings=0, exceeed_seq=18
input_metadata = InputMetadata(prompt_lens=[770], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[18], num_prompts=1, max_context_len=None,)
INFO 12-28 15:59:59 llm_engine.py:693] Avg past 5 seconds prompt throughput: 1697.3 tokens/s, Avg past 5 seconds real prompt throughput: 1647.2 tokens/s, Avg past 5 seconds generation throughput: 898.7 tokens/s, total prompt throughput: 269554.0 tokens/s, total real prompt throughput: 240295.0 tokens/s, total final prompt throughput: 151661.0 tokens/s, total generation throughput: 158291.0 tokens/s, avg total prompt throughput: 1793.2 tokens/s, avg total real prompt throughput: 1598.6 tokens/s, avg total final prompt throughput: 1008.9 tokens/s, avg total generation throughput: 1066.3 tokens/s, Running: 29 reqs, Swapped: 0 reqs, Waiting: 325 reqs, GPU KV cache usage: 96.0%, CPU KV cache usage: 0.0%
input_metadata = InputMetadata(prompt_lens=[944], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=688, cur_paddings=0, exceeed_seq=264
input_metadata = InputMetadata(prompt_lens=[952], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=382, cur_paddings=255, exceeed_seq=137
input_metadata = InputMetadata(prompt_lens=[264, 9], num_prompts=2, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[137], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[963], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=594, cur_paddings=0, exceeed_seq=28
input_metadata = InputMetadata(prompt_lens=[622], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[28], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=595, cur_paddings=0, exceeed_seq=33
input_metadata = InputMetadata(prompt_lens=[628], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[33], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[164], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=467, cur_paddings=244, exceeed_seq=121
input_metadata = InputMetadata(prompt_lens=[344, 100], num_prompts=2, max_context_len=None,)
promt select exit padding exceed_paddings=702, cur_paddings=141, exceeed_seq=308
input_metadata = InputMetadata(prompt_lens=[121, 82, 19], num_prompts=3, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[308], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=921, cur_paddings=0, exceeed_seq=31
input_metadata = InputMetadata(prompt_lens=[952], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[31], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=376, cur_paddings=254, exceeed_seq=11
input_metadata = InputMetadata(prompt_lens=[86, 29, 30, 133], num_prompts=4, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[11], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[140, 18], num_prompts=2, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[168, 45], num_prompts=2, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[629], num_prompts=1, max_context_len=None,)
INFO 12-28 16:00:04 llm_engine.py:693] Avg past 5 seconds prompt throughput: 1754.8 tokens/s, Avg past 5 seconds real prompt throughput: 1519.7 tokens/s, Avg past 5 seconds generation throughput: 917.3 tokens/s, total prompt throughput: 278072.0 tokens/s, total real prompt throughput: 247674.0 tokens/s, total final prompt throughput: 157038.0 tokens/s, total generation throughput: 162897.0 tokens/s, avg total prompt throughput: 1790.1 tokens/s, avg total real prompt throughput: 1594.5 tokens/s, avg total final prompt throughput: 1011.0 tokens/s, avg total generation throughput: 1061.5 tokens/s, Running: 28 reqs, Swapped: 0 reqs, Waiting: 304 reqs, GPU KV cache usage: 95.7%, CPU KV cache usage: 0.0%
input_metadata = InputMetadata(prompt_lens=[645, 490], num_prompts=2, max_context_len=None,)
promt select exit padding exceed_paddings=365, cur_paddings=0, exceeed_seq=34
input_metadata = InputMetadata(prompt_lens=[399], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[34], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=641, cur_paddings=0, exceeed_seq=17
input_metadata = InputMetadata(prompt_lens=[658], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[17], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[762], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[785], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=986, cur_paddings=0, exceeed_seq=38
input_metadata = InputMetadata(prompt_lens=[1024], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[38, 19], num_prompts=2, max_context_len=None,)
promt select exit padding exceed_paddings=987, cur_paddings=0, exceeed_seq=54
input_metadata = InputMetadata(prompt_lens=[1041], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=1568, cur_paddings=20, exceeed_seq=828
input_metadata = InputMetadata(prompt_lens=[54, 34], num_prompts=2, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[828], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[652], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[658], num_prompts=1, max_context_len=None,)
INFO 12-28 16:00:09 llm_engine.py:693] Avg past 5 seconds prompt throughput: 1577.9 tokens/s, Avg past 5 seconds real prompt throughput: 1538.0 tokens/s, Avg past 5 seconds generation throughput: 908.7 tokens/s, total prompt throughput: 286375.0 tokens/s, total real prompt throughput: 255783.0 tokens/s, total final prompt throughput: 162588.0 tokens/s, total generation throughput: 167466.0 tokens/s, avg total prompt throughput: 1785.8 tokens/s, avg total real prompt throughput: 1595.1 tokens/s, avg total final prompt throughput: 1013.9 tokens/s, avg total generation throughput: 1056.7 tokens/s, Running: 25 reqs, Swapped: 0 reqs, Waiting: 293 reqs, GPU KV cache usage: 93.1%, CPU KV cache usage: 0.0%
input_metadata = InputMetadata(prompt_lens=[668], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=459, cur_paddings=0, exceeed_seq=64
input_metadata = InputMetadata(prompt_lens=[523], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[64], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=694, cur_paddings=0, exceeed_seq=7
input_metadata = InputMetadata(prompt_lens=[701], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[7, 25], num_prompts=2, max_context_len=None,)
promt select exit padding exceed_paddings=901, cur_paddings=0, exceeed_seq=26
input_metadata = InputMetadata(prompt_lens=[927], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[26], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=305, cur_paddings=230, exceeed_seq=12
input_metadata = InputMetadata(prompt_lens=[38, 13, 87, 30, 37], num_prompts=5, max_context_len=None,)
promt select exit padding exceed_paddings=715, cur_paddings=127, exceeed_seq=288
input_metadata = InputMetadata(prompt_lens=[12, 92, 45], num_prompts=3, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[288, 164, 211], num_prompts=3, max_context_len=None,)
promt select exit padding exceed_paddings=492, cur_paddings=0, exceeed_seq=536
input_metadata = InputMetadata(prompt_lens=[44], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[536], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=536, cur_paddings=0, exceeed_seq=24
input_metadata = InputMetadata(prompt_lens=[560], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[24], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=332, cur_paddings=0, exceeed_seq=16
input_metadata = InputMetadata(prompt_lens=[348], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=589, cur_paddings=9, exceeed_seq=306
input_metadata = InputMetadata(prompt_lens=[16, 7], num_prompts=2, max_context_len=None,)
promt select exit padding exceed_paddings=279, cur_paddings=0, exceeed_seq=27
input_metadata = InputMetadata(prompt_lens=[306], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[27, 13, 6], num_prompts=3, max_context_len=None,)
promt select exit padding exceed_paddings=310, cur_paddings=0, exceeed_seq=367
input_metadata = InputMetadata(prompt_lens=[57], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=333, cur_paddings=0, exceeed_seq=34
input_metadata = InputMetadata(prompt_lens=[367], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[34, 24], num_prompts=2, max_context_len=None,)
promt select exit padding exceed_paddings=280, cur_paddings=0, exceeed_seq=34
input_metadata = InputMetadata(prompt_lens=[314], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[34, 19, 12], num_prompts=3, max_context_len=None,)
INFO 12-28 16:00:14 llm_engine.py:693] Avg past 5 seconds prompt throughput: 1471.4 tokens/s, Avg past 5 seconds real prompt throughput: 1343.9 tokens/s, Avg past 5 seconds generation throughput: 979.3 tokens/s, total prompt throughput: 294304.0 tokens/s, total real prompt throughput: 263082.0 tokens/s, total final prompt throughput: 167765.0 tokens/s, total generation throughput: 172306.0 tokens/s, avg total prompt throughput: 1779.6 tokens/s, avg total real prompt throughput: 1590.8 tokens/s, avg total final prompt throughput: 1014.4 tokens/s, avg total generation throughput: 1053.8 tokens/s, Running: 34 reqs, Swapped: 0 reqs, Waiting: 265 reqs, GPU KV cache usage: 99.9%, CPU KV cache usage: 0.0%
promt select exit padding exceed_paddings=282, cur_paddings=0, exceeed_seq=63
input_metadata = InputMetadata(prompt_lens=[345], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[63, 46, 38], num_prompts=3, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[723], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=337, cur_paddings=0, exceeed_seq=136
input_metadata = InputMetadata(prompt_lens=[473], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[136], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[144, 119, 98, 86], num_prompts=4, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[94], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[737, 892], num_prompts=2, max_context_len=None,)
promt select exit padding exceed_paddings=475, cur_paddings=0, exceeed_seq=112
input_metadata = InputMetadata(prompt_lens=[587], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[112, 14], num_prompts=2, max_context_len=None,)
promt select exit padding exceed_paddings=374, cur_paddings=0, exceeed_seq=189
input_metadata = InputMetadata(prompt_lens=[563], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[189], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[583], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[203], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=934, cur_paddings=250, exceeed_seq=468
input_metadata = InputMetadata(prompt_lens=[210, 240, 20], num_prompts=3, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[468], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[457], num_prompts=1, max_context_len=None,)
INFO 12-28 16:00:19 llm_engine.py:693] Avg past 5 seconds prompt throughput: 1606.5 tokens/s, Avg past 5 seconds real prompt throughput: 1468.7 tokens/s, Avg past 5 seconds generation throughput: 923.7 tokens/s, total prompt throughput: 302263.0 tokens/s, total real prompt throughput: 270330.0 tokens/s, total final prompt throughput: 171573.0 tokens/s, total generation throughput: 176947.0 tokens/s, avg total prompt throughput: 1773.9 tokens/s, avg total real prompt throughput: 1586.5 tokens/s, avg total final prompt throughput: 1006.9 tokens/s, avg total generation throughput: 1050.0 tokens/s, Running: 30 reqs, Swapped: 0 reqs, Waiting: 252 reqs, GPU KV cache usage: 97.8%, CPU KV cache usage: 0.0%
promt select exit padding exceed_paddings=322, cur_paddings=0, exceeed_seq=8
input_metadata = InputMetadata(prompt_lens=[330], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=278, cur_paddings=0, exceeed_seq=286
input_metadata = InputMetadata(prompt_lens=[8], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=281, cur_paddings=0, exceeed_seq=5
input_metadata = InputMetadata(prompt_lens=[286], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[5], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=423, cur_paddings=0, exceeed_seq=73
input_metadata = InputMetadata(prompt_lens=[496], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[73, 55, 6], num_prompts=3, max_context_len=None,)
promt select exit padding exceed_paddings=444, cur_paddings=0, exceeed_seq=65
input_metadata = InputMetadata(prompt_lens=[509], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=366, cur_paddings=50, exceeed_seq=223
input_metadata = InputMetadata(prompt_lens=[65, 15], num_prompts=2, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[223], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[12, 29], num_prompts=2, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[41], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=474, cur_paddings=0, exceeed_seq=8
input_metadata = InputMetadata(prompt_lens=[482], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[8, 12], num_prompts=2, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[15, 18], num_prompts=2, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[1003], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[1012], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[1017], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=591, cur_paddings=224, exceeed_seq=8
input_metadata = InputMetadata(prompt_lens=[375, 151], num_prompts=2, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[8, 38, 12], num_prompts=3, max_context_len=None,)
promt select exit padding exceed_paddings=1141, cur_paddings=27, exceeed_seq=616
input_metadata = InputMetadata(prompt_lens=[59, 32], num_prompts=2, max_context_len=None,)
promt select exit padding exceed_paddings=607, cur_paddings=0, exceeed_seq=9
input_metadata = InputMetadata(prompt_lens=[616], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[9], num_prompts=1, max_context_len=None,)
INFO 12-28 16:00:24 llm_engine.py:693] Avg past 5 seconds prompt throughput: 1564.4 tokens/s, Avg past 5 seconds real prompt throughput: 1466.9 tokens/s, Avg past 5 seconds generation throughput: 957.1 tokens/s, total prompt throughput: 310197.0 tokens/s, total real prompt throughput: 277798.0 tokens/s, total final prompt throughput: 177275.0 tokens/s, total generation throughput: 181742.0 tokens/s, avg total prompt throughput: 1768.5 tokens/s, avg total real prompt throughput: 1583.8 tokens/s, avg total final prompt throughput: 1010.7 tokens/s, avg total generation throughput: 1047.4 tokens/s, Running: 31 reqs, Swapped: 0 reqs, Waiting: 229 reqs, GPU KV cache usage: 98.6%, CPU KV cache usage: 0.0%
input_metadata = InputMetadata(prompt_lens=[214], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=278, cur_paddings=152, exceeed_seq=95
input_metadata = InputMetadata(prompt_lens=[221, 69], num_prompts=2, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[95, 66], num_prompts=2, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[83, 107, 73], num_prompts=3, max_context_len=None,)
promt select exit padding exceed_paddings=608, cur_paddings=0, exceeed_seq=19
input_metadata = InputMetadata(prompt_lens=[627], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[19], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=486, cur_paddings=0, exceeed_seq=7
input_metadata = InputMetadata(prompt_lens=[493], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[7], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=489, cur_paddings=0, exceeed_seq=13
input_metadata = InputMetadata(prompt_lens=[502], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[13], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=963, cur_paddings=0, exceeed_seq=59
input_metadata = InputMetadata(prompt_lens=[1022], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[59, 62, 18, 49, 39], num_prompts=5, max_context_len=None,)
promt select exit padding exceed_paddings=482, cur_paddings=0, exceeed_seq=180
input_metadata = InputMetadata(prompt_lens=[662], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=507, cur_paddings=190, exceeed_seq=53
input_metadata = InputMetadata(prompt_lens=[180, 370], num_prompts=2, max_context_len=None,)
promt select exit padding exceed_paddings=523, cur_paddings=21, exceeed_seq=304
input_metadata = InputMetadata(prompt_lens=[53, 32], num_prompts=2, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[304], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=1422, cur_paddings=214, exceeed_seq=911
input_metadata = InputMetadata(prompt_lens=[307, 93], num_prompts=2, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[911], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[316, 88], num_prompts=2, max_context_len=None,)
promt select exit padding exceed_paddings=331, cur_paddings=0, exceeed_seq=66
input_metadata = InputMetadata(prompt_lens=[397], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[66], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[18, 17], num_prompts=2, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[475], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=295, cur_paddings=0, exceeed_seq=184
input_metadata = InputMetadata(prompt_lens=[479], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=324, cur_paddings=166, exceeed_seq=26
input_metadata = InputMetadata(prompt_lens=[184, 18], num_prompts=2, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[26], num_prompts=1, max_context_len=None,)
INFO 12-28 16:00:29 llm_engine.py:693] Avg past 5 seconds prompt throughput: 2609.5 tokens/s, Avg past 5 seconds real prompt throughput: 2310.0 tokens/s, Avg past 5 seconds generation throughput: 845.7 tokens/s, total prompt throughput: 320156.0 tokens/s, total real prompt throughput: 286615.0 tokens/s, total final prompt throughput: 183217.0 tokens/s, total generation throughput: 186000.0 tokens/s, avg total prompt throughput: 1774.4 tokens/s, avg total real prompt throughput: 1588.5 tokens/s, avg total final prompt throughput: 1015.5 tokens/s, avg total generation throughput: 1041.7 tokens/s, Running: 39 reqs, Swapped: 0 reqs, Waiting: 203 reqs, GPU KV cache usage: 98.7%, CPU KV cache usage: 0.0%
input_metadata = InputMetadata(prompt_lens=[262], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=518, cur_paddings=2, exceeed_seq=543
input_metadata = InputMetadata(prompt_lens=[283, 285], num_prompts=2, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[543], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[547], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[552, 425], num_prompts=2, max_context_len=None,)
promt select exit padding exceed_paddings=276, cur_paddings=237, exceeed_seq=383
input_metadata = InputMetadata(prompt_lens=[185, 422], num_prompts=2, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[383], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=843, cur_paddings=0, exceeed_seq=36
input_metadata = InputMetadata(prompt_lens=[879], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[36, 23], num_prompts=2, max_context_len=None,)
promt select exit padding exceed_paddings=277, cur_paddings=0, exceeed_seq=303
input_metadata = InputMetadata(prompt_lens=[580], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[303], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=419, cur_paddings=0, exceeed_seq=192
input_metadata = InputMetadata(prompt_lens=[611], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[192, 84], num_prompts=2, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[199, 88], num_prompts=2, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[387], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=665, cur_paddings=0, exceeed_seq=7
input_metadata = InputMetadata(prompt_lens=[672], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[7, 18, 25], num_prompts=3, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[682], num_prompts=1, max_context_len=None,)
INFO 12-28 16:00:34 llm_engine.py:693] Avg past 5 seconds prompt throughput: 1841.4 tokens/s, Avg past 5 seconds real prompt throughput: 1708.2 tokens/s, Avg past 5 seconds generation throughput: 942.0 tokens/s, total prompt throughput: 328796.0 tokens/s, total real prompt throughput: 294632.0 tokens/s, total final prompt throughput: 189565.0 tokens/s, total generation throughput: 190803.0 tokens/s, avg total prompt throughput: 1772.6 tokens/s, avg total real prompt throughput: 1588.4 tokens/s, avg total final prompt throughput: 1022.0 tokens/s, avg total generation throughput: 1039.2 tokens/s, Running: 32 reqs, Swapped: 0 reqs, Waiting: 186 reqs, GPU KV cache usage: 99.0%, CPU KV cache usage: 0.0%
promt select exit padding exceed_paddings=672, cur_paddings=0, exceeed_seq=17
input_metadata = InputMetadata(prompt_lens=[689], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=864, cur_paddings=24, exceeed_seq=314
input_metadata = InputMetadata(prompt_lens=[17, 27, 34], num_prompts=3, max_context_len=None,)
promt select exit padding exceed_paddings=376, cur_paddings=0, exceeed_seq=690
input_metadata = InputMetadata(prompt_lens=[314], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[690], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=571, cur_paddings=0, exceeed_seq=7
input_metadata = InputMetadata(prompt_lens=[578], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=1445, cur_paddings=1, exceeed_seq=729
input_metadata = InputMetadata(prompt_lens=[7, 6], num_prompts=2, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[729], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=531, cur_paddings=0, exceeed_seq=206
input_metadata = InputMetadata(prompt_lens=[737], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[206], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=341, cur_paddings=0, exceeed_seq=12
input_metadata = InputMetadata(prompt_lens=[353], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=337, cur_paddings=0, exceeed_seq=349
input_metadata = InputMetadata(prompt_lens=[12], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=342, cur_paddings=0, exceeed_seq=7
input_metadata = InputMetadata(prompt_lens=[349], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[7], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=342, cur_paddings=0, exceeed_seq=13
input_metadata = InputMetadata(prompt_lens=[355], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[13], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=355, cur_paddings=113, exceeed_seq=68
input_metadata = InputMetadata(prompt_lens=[197, 310], num_prompts=2, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[68, 8], num_prompts=2, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[308], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[82, 21], num_prompts=2, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[242], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=304, cur_paddings=0, exceeed_seq=41
input_metadata = InputMetadata(prompt_lens=[345], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=273, cur_paddings=0, exceeed_seq=314
input_metadata = InputMetadata(prompt_lens=[41], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[314], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=382, cur_paddings=83, exceeed_seq=18
input_metadata = InputMetadata(prompt_lens=[317, 234], num_prompts=2, max_context_len=None,)
promt select exit padding exceed_paddings=494, cur_paddings=0, exceeed_seq=512
input_metadata = InputMetadata(prompt_lens=[18], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=435, cur_paddings=0, exceeed_seq=77
input_metadata = InputMetadata(prompt_lens=[512], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=338, cur_paddings=0, exceeed_seq=415
input_metadata = InputMetadata(prompt_lens=[77], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=320, cur_paddings=0, exceeed_seq=95
input_metadata = InputMetadata(prompt_lens=[415], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[95], num_prompts=1, max_context_len=None,)
INFO 12-28 16:00:39 llm_engine.py:693] Avg past 5 seconds prompt throughput: 2028.6 tokens/s, Avg past 5 seconds real prompt throughput: 1951.3 tokens/s, Avg past 5 seconds generation throughput: 908.0 tokens/s, total prompt throughput: 338452.0 tokens/s, total real prompt throughput: 303946.0 tokens/s, total final prompt throughput: 194963.0 tokens/s, total generation throughput: 195354.0 tokens/s, avg total prompt throughput: 1776.7 tokens/s, avg total real prompt throughput: 1595.6 tokens/s, avg total final prompt throughput: 1023.5 tokens/s, avg total generation throughput: 1035.7 tokens/s, Running: 38 reqs, Swapped: 0 reqs, Waiting: 161 reqs, GPU KV cache usage: 93.4%, CPU KV cache usage: 0.0%
input_metadata = InputMetadata(prompt_lens=[856], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[15], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=844, cur_paddings=0, exceeed_seq=23
input_metadata = InputMetadata(prompt_lens=[867], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[23], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=892, cur_paddings=0, exceeed_seq=26
input_metadata = InputMetadata(prompt_lens=[918], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[26, 92, 6], num_prompts=3, max_context_len=None,)
promt select exit padding exceed_paddings=893, cur_paddings=0, exceeed_seq=33
input_metadata = InputMetadata(prompt_lens=[926], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[33, 96, 10], num_prompts=3, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[937], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[43], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=272, cur_paddings=181, exceeed_seq=57
input_metadata = InputMetadata(prompt_lens=[101, 14, 148], num_prompts=3, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[57, 25, 15], num_prompts=3, max_context_len=None,)
promt select exit padding exceed_paddings=539, cur_paddings=0, exceeed_seq=25
input_metadata = InputMetadata(prompt_lens=[564], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[25, 35, 11], num_prompts=3, max_context_len=None,)
INFO 12-28 16:00:44 llm_engine.py:693] Avg past 5 seconds prompt throughput: 1282.3 tokens/s, Avg past 5 seconds real prompt throughput: 1169.6 tokens/s, Avg past 5 seconds generation throughput: 1000.7 tokens/s, total prompt throughput: 344875.0 tokens/s, total real prompt throughput: 309813.0 tokens/s, total final prompt throughput: 197780.0 tokens/s, total generation throughput: 200301.0 tokens/s, avg total prompt throughput: 1763.9 tokens/s, avg total real prompt throughput: 1584.6 tokens/s, avg total final prompt throughput: 1011.6 tokens/s, avg total generation throughput: 1034.4 tokens/s, Running: 34 reqs, Swapped: 0 reqs, Waiting: 147 reqs, GPU KV cache usage: 97.8%, CPU KV cache usage: 0.0%
promt select exit padding exceed_paddings=612, cur_paddings=0, exceeed_seq=74
input_metadata = InputMetadata(prompt_lens=[686], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[74, 8, 9], num_prompts=3, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[310, 338], num_prompts=2, max_context_len=None,)
promt select exit padding exceed_paddings=364, cur_paddings=0, exceeed_seq=137
input_metadata = InputMetadata(prompt_lens=[501], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[137], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=1594, cur_paddings=187, exceeed_seq=612
input_metadata = InputMetadata(prompt_lens=[143, 81, 18], num_prompts=3, max_context_len=None,)
promt select exit padding exceed_paddings=508, cur_paddings=0, exceeed_seq=104
input_metadata = InputMetadata(prompt_lens=[612], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=284, cur_paddings=160, exceeed_seq=14
input_metadata = InputMetadata(prompt_lens=[104, 138, 12], num_prompts=3, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[14], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=764, cur_paddings=0, exceeed_seq=135
input_metadata = InputMetadata(prompt_lens=[899], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[135, 97], num_prompts=2, max_context_len=None,)
promt select exit padding exceed_paddings=503, cur_paddings=0, exceeed_seq=26
input_metadata = InputMetadata(prompt_lens=[529], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[26, 50], num_prompts=2, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[752], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=685, cur_paddings=0, exceeed_seq=72
input_metadata = InputMetadata(prompt_lens=[757], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[72, 6, 7], num_prompts=3, max_context_len=None,)
promt select exit padding exceed_paddings=1395, cur_paddings=132, exceeed_seq=505
input_metadata = InputMetadata(prompt_lens=[84, 18, 18], num_prompts=3, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[505], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=411, cur_paddings=0, exceeed_seq=16
input_metadata = InputMetadata(prompt_lens=[427], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=313, cur_paddings=3, exceeed_seq=171
input_metadata = InputMetadata(prompt_lens=[16, 13], num_prompts=2, max_context_len=None,)
promt select exit padding exceed_paddings=261, cur_paddings=165, exceeed_seq=219
input_metadata = InputMetadata(prompt_lens=[171, 6], num_prompts=2, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[219], num_prompts=1, max_context_len=None,)
INFO 12-28 16:00:49 llm_engine.py:693] Avg past 5 seconds prompt throughput: 1932.1 tokens/s, Avg past 5 seconds real prompt throughput: 1712.1 tokens/s, Avg past 5 seconds generation throughput: 965.5 tokens/s, total prompt throughput: 353752.0 tokens/s, total real prompt throughput: 317657.0 tokens/s, total final prompt throughput: 204604.0 tokens/s, total generation throughput: 205150.0 tokens/s, avg total prompt throughput: 1764.0 tokens/s, avg total real prompt throughput: 1584.0 tokens/s, avg total final prompt throughput: 1020.3 tokens/s, avg total generation throughput: 1032.7 tokens/s, Running: 41 reqs, Swapped: 0 reqs, Waiting: 115 reqs, GPU KV cache usage: 99.6%, CPU KV cache usage: 0.0%
promt select exit padding exceed_paddings=320, cur_paddings=154, exceeed_seq=16
input_metadata = InputMetadata(prompt_lens=[28, 182], num_prompts=2, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[16], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[224], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[913], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=523, cur_paddings=0, exceeed_seq=47
input_metadata = InputMetadata(prompt_lens=[570], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=372, cur_paddings=0, exceeed_seq=419
input_metadata = InputMetadata(prompt_lens=[47], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[419], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=336, cur_paddings=0, exceeed_seq=90
input_metadata = InputMetadata(prompt_lens=[426], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=345, cur_paddings=0, exceeed_seq=435
input_metadata = InputMetadata(prompt_lens=[90], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=425, cur_paddings=0, exceeed_seq=10
input_metadata = InputMetadata(prompt_lens=[435], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=281, cur_paddings=201, exceeed_seq=35
input_metadata = InputMetadata(prompt_lens=[10, 115, 19], num_prompts=3, max_context_len=None,)
promt select exit padding exceed_paddings=305, cur_paddings=219, exceeed_seq=64
input_metadata = InputMetadata(prompt_lens=[35, 46, 150], num_prompts=3, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[64], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=372, cur_paddings=231, exceeed_seq=16
input_metadata = InputMetadata(prompt_lens=[157, 69, 14], num_prompts=3, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[16], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[156, 58, 73], num_prompts=3, max_context_len=None,)
promt select exit padding exceed_paddings=285, cur_paddings=197, exceeed_seq=80
input_metadata = InputMetadata(prompt_lens=[71, 168, 68], num_prompts=3, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[80, 81], num_prompts=2, max_context_len=None,)
promt select exit padding exceed_paddings=384, cur_paddings=238, exceeed_seq=33
input_metadata = InputMetadata(prompt_lens=[179, 88, 32], num_prompts=3, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[33], num_prompts=1, max_context_len=None,)
INFO 12-28 16:00:54 llm_engine.py:693] Avg past 5 seconds prompt throughput: 1406.2 tokens/s, Avg past 5 seconds real prompt throughput: 1099.6 tokens/s, Avg past 5 seconds generation throughput: 1089.3 tokens/s, total prompt throughput: 360492.0 tokens/s, total real prompt throughput: 322975.0 tokens/s, total final prompt throughput: 207766.0 tokens/s, total generation throughput: 210626.0 tokens/s, avg total prompt throughput: 1753.7 tokens/s, avg total real prompt throughput: 1571.2 tokens/s, avg total final prompt throughput: 1010.7 tokens/s, avg total generation throughput: 1034.1 tokens/s, Running: 37 reqs, Swapped: 0 reqs, Waiting: 100 reqs, GPU KV cache usage: 94.9%, CPU KV cache usage: 0.0%
promt select exit padding exceed_paddings=1001, cur_paddings=0, exceeed_seq=9
input_metadata = InputMetadata(prompt_lens=[1010], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=335, cur_paddings=5, exceeed_seq=121
input_metadata = InputMetadata(prompt_lens=[9, 11, 8], num_prompts=3, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[121, 19, 37], num_prompts=3, max_context_len=None,)
promt select exit padding exceed_paddings=1001, cur_paddings=0, exceeed_seq=37
input_metadata = InputMetadata(prompt_lens=[1038], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=319, cur_paddings=214, exceeed_seq=37
input_metadata = InputMetadata(prompt_lens=[37, 33, 142], num_prompts=3, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[37], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[43], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=744, cur_paddings=201, exceeed_seq=329
input_metadata = InputMetadata(prompt_lens=[148, 42, 53], num_prompts=3, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[329], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=267, cur_paddings=0, exceeed_seq=338
input_metadata = InputMetadata(prompt_lens=[71], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=293, cur_paddings=191, exceeed_seq=236
input_metadata = InputMetadata(prompt_lens=[338, 147], num_prompts=2, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[236, 20], num_prompts=2, max_context_len=None,)
promt select exit padding exceed_paddings=315, cur_paddings=217, exceeed_seq=144
input_metadata = InputMetadata(prompt_lens=[242, 25], num_prompts=2, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[144], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[251, 33], num_prompts=2, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[261, 41], num_prompts=2, max_context_len=None,)
promt select exit padding exceed_paddings=343, cur_paddings=222, exceeed_seq=148
input_metadata = InputMetadata(prompt_lens=[269, 47], num_prompts=2, max_context_len=None,)
promt select exit padding exceed_paddings=356, cur_paddings=0, exceeed_seq=504
input_metadata = InputMetadata(prompt_lens=[148], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=469, cur_paddings=0, exceeed_seq=35
input_metadata = InputMetadata(prompt_lens=[504], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[35, 33], num_prompts=2, max_context_len=None,)
promt select exit padding exceed_paddings=314, cur_paddings=0, exceeed_seq=15
input_metadata = InputMetadata(prompt_lens=[329], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=1391, cur_paddings=55, exceeed_seq=366
input_metadata = InputMetadata(prompt_lens=[15, 32, 13, 13], num_prompts=4, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[366], num_prompts=1, max_context_len=None,)
INFO 12-28 16:00:59 llm_engine.py:693] Avg past 5 seconds prompt throughput: 1801.0 tokens/s, Avg past 5 seconds real prompt throughput: 1379.1 tokens/s, Avg past 5 seconds generation throughput: 1006.1 tokens/s, total prompt throughput: 368836.0 tokens/s, total real prompt throughput: 329372.0 tokens/s, total final prompt throughput: 210831.0 tokens/s, total generation throughput: 215680.0 tokens/s, avg total prompt throughput: 1751.6 tokens/s, avg total real prompt throughput: 1564.2 tokens/s, avg total final prompt throughput: 1001.2 tokens/s, avg total generation throughput: 1033.5 tokens/s, Running: 39 reqs, Swapped: 0 reqs, Waiting: 79 reqs, GPU KV cache usage: 97.5%, CPU KV cache usage: 0.0%
input_metadata = InputMetadata(prompt_lens=[554], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[445], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=361, cur_paddings=0, exceeed_seq=26
input_metadata = InputMetadata(prompt_lens=[387], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[26], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=362, cur_paddings=0, exceeed_seq=32
input_metadata = InputMetadata(prompt_lens=[394], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=418, cur_paddings=203, exceeed_seq=20
input_metadata = InputMetadata(prompt_lens=[32, 235], num_prompts=2, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[20, 9, 13], num_prompts=3, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[16, 19], num_prompts=2, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[358], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=907, cur_paddings=0, exceeed_seq=10
input_metadata = InputMetadata(prompt_lens=[917], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[10, 126], num_prompts=2, max_context_len=None,)
promt select exit padding exceed_paddings=908, cur_paddings=0, exceeed_seq=28
input_metadata = InputMetadata(prompt_lens=[936], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[28, 138], num_prompts=2, max_context_len=None,)
INFO 12-28 16:01:04 llm_engine.py:693] Avg past 5 seconds prompt throughput: 1102.3 tokens/s, Avg past 5 seconds real prompt throughput: 1024.8 tokens/s, Avg past 5 seconds generation throughput: 1114.3 tokens/s, total prompt throughput: 374039.0 tokens/s, total real prompt throughput: 334235.0 tokens/s, total final prompt throughput: 214297.0 tokens/s, total generation throughput: 221275.0 tokens/s, avg total prompt throughput: 1735.0 tokens/s, avg total real prompt throughput: 1550.4 tokens/s, avg total final prompt throughput: 994.0 tokens/s, avg total generation throughput: 1035.4 tokens/s, Running: 32 reqs, Swapped: 0 reqs, Waiting: 67 reqs, GPU KV cache usage: 97.5%, CPU KV cache usage: 0.0%
promt select exit padding exceed_paddings=663, cur_paddings=0, exceeed_seq=12
input_metadata = InputMetadata(prompt_lens=[675], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=295, cur_paddings=0, exceeed_seq=307
input_metadata = InputMetadata(prompt_lens=[12], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[307], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[314], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[656], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[584], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[89], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[870], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[678], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=374, cur_paddings=0, exceeed_seq=13
input_metadata = InputMetadata(prompt_lens=[387], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[13], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=509, cur_paddings=0, exceeed_seq=16
input_metadata = InputMetadata(prompt_lens=[525], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=374, cur_paddings=0, exceeed_seq=390
input_metadata = InputMetadata(prompt_lens=[16], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=289, cur_paddings=0, exceeed_seq=101
input_metadata = InputMetadata(prompt_lens=[390], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[101], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[107], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[118], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=839, cur_paddings=0, exceeed_seq=18
input_metadata = InputMetadata(prompt_lens=[857], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[18], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[197], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=746, cur_paddings=0, exceeed_seq=58
input_metadata = InputMetadata(prompt_lens=[804], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[58, 49, 77], num_prompts=3, max_context_len=None,)
promt select exit padding exceed_paddings=545, cur_paddings=154, exceeed_seq=107
input_metadata = InputMetadata(prompt_lens=[498, 344], num_prompts=2, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[107], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=536, cur_paddings=240, exceeed_seq=55
input_metadata = InputMetadata(prompt_lens=[351, 111], num_prompts=2, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[55, 12, 14, 22], num_prompts=4, max_context_len=None,)
promt select exit padding exceed_paddings=401, cur_paddings=0, exceeed_seq=42
input_metadata = InputMetadata(prompt_lens=[443], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[42, 61, 78], num_prompts=3, max_context_len=None,)
promt select exit padding exceed_paddings=443, cur_paddings=77, exceeed_seq=204
input_metadata = InputMetadata(prompt_lens=[82, 57, 30], num_prompts=3, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[204], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[206], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=456, cur_paddings=23, exceeed_seq=14
input_metadata = InputMetadata(prompt_lens=[424, 447], num_prompts=2, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[14], num_prompts=1, max_context_len=None,)
INFO 12-28 16:01:09 llm_engine.py:693] Avg past 5 seconds prompt throughput: 2492.7 tokens/s, Avg past 5 seconds real prompt throughput: 2347.4 tokens/s, Avg past 5 seconds generation throughput: 921.1 tokens/s, total prompt throughput: 386516.0 tokens/s, total real prompt throughput: 345891.0 tokens/s, total final prompt throughput: 224498.0 tokens/s, total generation throughput: 225890.0 tokens/s, avg total prompt throughput: 1752.2 tokens/s, avg total real prompt throughput: 1568.0 tokens/s, avg total final prompt throughput: 1017.7 tokens/s, avg total generation throughput: 1032.8 tokens/s, Running: 43 reqs, Swapped: 0 reqs, Waiting: 29 reqs, GPU KV cache usage: 99.9%, CPU KV cache usage: 0.0%
promt select exit padding exceed_paddings=411, cur_paddings=0, exceeed_seq=35
input_metadata = InputMetadata(prompt_lens=[446], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[35], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=424, cur_paddings=0, exceeed_seq=27
input_metadata = InputMetadata(prompt_lens=[451], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[27, 10, 85], num_prompts=3, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[87], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[63, 48, 31, 101, 94], num_prompts=5, max_context_len=None,)
promt select exit padding exceed_paddings=427, cur_paddings=0, exceeed_seq=62
input_metadata = InputMetadata(prompt_lens=[489], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[62, 42, 108], num_prompts=3, max_context_len=None,)
promt select exit padding exceed_paddings=260, cur_paddings=146, exceeed_seq=131
input_metadata = InputMetadata(prompt_lens=[99, 245], num_prompts=2, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[131, 255], num_prompts=2, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[167], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[952], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[958], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=457, cur_paddings=0, exceeed_seq=63
input_metadata = InputMetadata(prompt_lens=[520], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=936, cur_paddings=0, exceeed_seq=999
input_metadata = InputMetadata(prompt_lens=[63], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[999], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=541, cur_paddings=0, exceeed_seq=463
input_metadata = InputMetadata(prompt_lens=[1004], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=332, cur_paddings=0, exceeed_seq=131
input_metadata = InputMetadata(prompt_lens=[463], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[131, 369], num_prompts=2, max_context_len=None,)
promt select exit padding exceed_paddings=623, cur_paddings=0, exceeed_seq=10
input_metadata = InputMetadata(prompt_lens=[633], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[10], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=595, cur_paddings=0, exceeed_seq=42
input_metadata = InputMetadata(prompt_lens=[637], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[42], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[52], num_prompts=1, max_context_len=None,)
promt select exit padding exceed_paddings=425, cur_paddings=34, exceeed_seq=24
input_metadata = InputMetadata(prompt_lens=[415, 381], num_prompts=2, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[24, 187], num_prompts=2, max_context_len=None,)
INFO 12-28 16:01:14 llm_engine.py:693] Avg past 5 seconds prompt throughput: 2418.3 tokens/s, Avg past 5 seconds real prompt throughput: 2220.2 tokens/s, Avg past 5 seconds generation throughput: 1040.0 tokens/s, total prompt throughput: 398190.0 tokens/s, total real prompt throughput: 356610.0 tokens/s, total final prompt throughput: 231585.0 tokens/s, total generation throughput: 231115.0 tokens/s, avg total prompt throughput: 1765.0 tokens/s, avg total real prompt throughput: 1580.7 tokens/s, avg total final prompt throughput: 1026.5 tokens/s, avg total generation throughput: 1033.0 tokens/s, Running: 39 reqs, Swapped: 0 reqs, Waiting: 6 reqs, GPU KV cache usage: 99.7%, CPU KV cache usage: 0.0%
promt select exit padding exceed_paddings=357, cur_paddings=0, exceeed_seq=42
input_metadata = InputMetadata(prompt_lens=[399], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[42, 197], num_prompts=2, max_context_len=None,)
promt select exit padding exceed_paddings=472, cur_paddings=57, exceeed_seq=50
input_metadata = InputMetadata(prompt_lens=[465, 408], num_prompts=2, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[50, 202], num_prompts=2, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[63], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[211], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[220], num_prompts=1, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[464, 310], num_prompts=2, max_context_len=None,)
promt select exit padding exceed_paddings=544, cur_paddings=197, exceeed_seq=9
input_metadata = InputMetadata(prompt_lens=[356, 159], num_prompts=2, max_context_len=None,)
input_metadata = InputMetadata(prompt_lens=[9], num_prompts=1, max_context_len=None,)
INFO 12-28 16:01:19 llm_engine.py:693] Avg past 5 seconds prompt throughput: 913.4 tokens/s, Avg past 5 seconds real prompt throughput: 760.1 tokens/s, Avg past 5 seconds generation throughput: 1103.6 tokens/s, total prompt throughput: 402825.0 tokens/s, total real prompt throughput: 360367.0 tokens/s, total final prompt throughput: 233085.0 tokens/s, total generation throughput: 236662.0 tokens/s, avg total prompt throughput: 1746.7 tokens/s, avg total real prompt throughput: 1562.6 tokens/s, avg total final prompt throughput: 1010.7 tokens/s, avg total generation throughput: 1034.6 tokens/s, Running: 26 reqs, Swapped: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 90.4%, CPU KV cache usage: 0.0%
INFO 12-28 16:01:24 llm_engine.py:693] Avg past 5 seconds prompt throughput: 0.0 tokens/s, Avg past 5 seconds real prompt throughput: 0.0 tokens/s, Avg past 5 seconds generation throughput: 755.9 tokens/s, total prompt throughput: 402825.0 tokens/s, total real prompt throughput: 360367.0 tokens/s, total final prompt throughput: 233085.0 tokens/s, total generation throughput: 240450.0 tokens/s, avg total prompt throughput: 1709.6 tokens/s, avg total real prompt throughput: 1529.4 tokens/s, avg total final prompt throughput: 989.2 tokens/s, avg total generation throughput: 1028.7 tokens/s, Running: 13 reqs, Swapped: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 59.0%, CPU KV cache usage: 0.0%
INFO 12-28 16:01:29 llm_engine.py:693] Avg past 5 seconds prompt throughput: 0.0 tokens/s, Avg past 5 seconds real prompt throughput: 0.0 tokens/s, Avg past 5 seconds generation throughput: 451.4 tokens/s, total prompt throughput: 402825.0 tokens/s, total real prompt throughput: 360367.0 tokens/s, total final prompt throughput: 233085.0 tokens/s, total generation throughput: 242712.0 tokens/s, avg total prompt throughput: 1674.0 tokens/s, avg total real prompt throughput: 1497.6 tokens/s, avg total final prompt throughput: 968.6 tokens/s, avg total generation throughput: 1016.6 tokens/s, Running: 7 reqs, Swapped: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 47.1%, CPU KV cache usage: 0.0%
Throughput: 4.07 requests/s, 1946.74 tokens/s
PromptThroughput: 948.88 tokens/s
OutputThroughput: 997.85 tokens/s
Total Time : 245.65 s
